import os
import numpy as np
import pickle
import torch
import torch.nn as nn
from collections import defaultdict, Counter
from itertools import product
from transformers import ViTImageProcessor, Trainer
import sys
sys.path.append('../')
from utils.constant import ViTExperiment
import evaluate

processor = ViTImageProcessor.from_pretrained(ViTExperiment.ViT_PATH)
met_acc = evaluate.load("accuracy")
met_f1 = evaluate.load("f1")

def transforms(batch):
    """
    ç”»åƒã®ãƒãƒƒãƒã‚’å‰å‡¦ç†ã™ã‚‹
    ãƒ©ãƒ™ãƒ«ã‚’è¡¨ã™ã‚«ãƒ©ãƒ åãŒlabel (c10) ã®å ´åˆã«é©ç”¨å¯èƒ½
    
    Parameters
    ------------------
    
    Returns
    ------------------
    
    """
    # ç”»åƒã®ãƒãƒƒãƒã‚’å¤‰æ›ã—ã¦torch.tensorã«ã™ã‚‹
    inputs = processor(images=batch["img"], return_tensors="pt")

    # ãƒ©ãƒ™ãƒ«ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚‚å‰å‡¦ç†æ™‚ã«è¿½åŠ 
    inputs["labels"] = batch["label"]
    return inputs

def transforms_c100(batch):
    """
    ç”»åƒã®ãƒãƒƒãƒã‚’å‰å‡¦ç†ã™ã‚‹
    ãƒ©ãƒ™ãƒ«ã‚’è¡¨ã™ã‚«ãƒ©ãƒ åãŒ fine_label (c100) ã®å ´åˆã«é©ç”¨å¯èƒ½
    
    Parameters
    ------------------
    
    Returns
    ------------------
    
    """
    # ç”»åƒã®ãƒãƒƒãƒã‚’å¤‰æ›ã—ã¦torch.tensorã«ã™ã‚‹
    inputs = processor(images=batch["img"], return_tensors="pt")

    # ãƒ©ãƒ™ãƒ«ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚‚å‰å‡¦ç†æ™‚ã«è¿½åŠ 
    inputs["labels"] = batch["fine_label"]
    
    if "ori_correct" in batch:
        inputs["ori_correct"] = batch["ori_correct"]
    return inputs

def pred_to_proba(pred):
    proba = torch.nn.functional.softmax(torch.tensor(pred.predictions), dim=-1)
    return proba.cpu().numpy()

def pred_to_labels(pred):
    # probaã«å¤‰æ›ã•ã‚ŒãŸnumpyé…åˆ—ã‚’å—ã‘å–ã‚‹å ´åˆ
    if isinstance(pred, np.ndarray):
        proba = pred
        labels = np.argmax(proba, axis=-1)
        return labels
    proba = torch.nn.functional.softmax(torch.tensor(pred.predictions), dim=-1)
    labels = torch.argmax(proba, dim=-1)
    return labels.cpu().numpy()

def compute_metrics(eval_pred):
    """
    äºˆæ¸¬çµæœã‹ã‚‰è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—ã™ã‚‹
    
    Parameters
    ------------------
    
    Returns
    ------------------
    
    """
    logits = eval_pred.predictions
    labels = eval_pred.label_ids
    predictions = np.argmax(logits, axis=-1)
    acc = met_acc.compute(predictions=predictions, references=labels)
    f1 = met_f1.compute(predictions=predictions, references=labels, average="macro")
    return {
        "accuracy": acc,
        "f1": f1,
    }

def count_pred_change(old_pred, new_pred):
    """
    ä¿®æ­£å‰å¾Œã®ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬çµæœã‚’æ¯”è¼ƒã—ã¦, ä¿®æ­£ã•ã‚ŒãŸã‚µãƒ³ãƒ—ãƒ«æ•°, å£Šã‚ŒãŸã‚µãƒ³ãƒ—ãƒ«ã‚’ç‰¹å®šã™ã‚‹
    
    Parameters
    ------------------
    old_pred: PredictionOutput
        ä¿®æ­£å‰ã®ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬çµæœ
    new_pred: PredictionOutput
        ä¿®æ­£å¾Œã®ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬çµæœ

    Returns
    ------------------
    result: dict
        4ç¨®é¡ã®ä¿®æ­£çµæœ (repaired, broken, non-repaired, non-broken) ã‚’ç¤ºã—ãŸè¾æ›¸.
        ã‚­ãƒ¼ãŒä¿®æ­£çµæœã®åå‰ï¼Œå€¤ãŒãã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ãƒªã‚¹ãƒˆ.
        NOTE: old_pred, new_predã¯åŒã˜è©•ä¾¡ç”¨ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹äºˆæ¸¬çµæœã§, shuffleã‚‚ã•ã‚Œã¦ã„ãªã„å‰æ.
    """
    old_labels = pred_to_labels(old_pred)
    new_labels = pred_to_labels(new_pred)
    true_labels = old_pred.label_ids
    # 4ç¨®é¡ã®åˆ¤å®šã‚’è¡Œã†
    # 1. ä¿®æ­£ã•ã‚ŒãŸã‚µãƒ³ãƒ—ãƒ«
    repaired = np.where((old_labels != true_labels) & (new_labels == true_labels))[0]
    # 2. å£Šã‚ŒãŸã‚µãƒ³ãƒ—ãƒ«
    broken = np.where((old_labels == true_labels) & (new_labels != true_labels))[0]
    # 3. ä¿®æ­£ã•ã‚Œã¦ã„ãªã„ã‚µãƒ³ãƒ—ãƒ«
    non_repaired = np.where((old_labels != true_labels) & (new_labels != true_labels))[0]
    # 4. å£Šã‚Œã¦ã„ãªã„ã‚µãƒ³ãƒ—ãƒ«
    non_broken = np.where((old_labels == true_labels) & (new_labels == true_labels))[0]
    result = {
        "repaired": repaired,
        "broken": broken,
        "non_repaired": non_repaired,
        "non_broken": non_broken
    }
    return result

def get_vscore(batch_neuron_values, abs=True, covavg=True):
    """
    ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã«å¯¾ã™ã‚‹vscoreã‚’è¿”ã™
    
    Parameters
    ------------------
    batch_neuron_values: numpy.ndarray
        ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®å€¤ã‚’è¡¨ã™è¡Œåˆ— (num_samples, num_neurons_of_tgt_layer)

    Returns
    ------------------
    vscore: numpy.ndarray
        ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã”ã¨ã®vscore (num_neurons_of_tgt_layer, )
    """
    # num_samplesãŒ1ä»¥ä¸‹ã®å ´åˆã¯, (num_neurons_of_tgt_layer, ) ã®å½¢çŠ¶ã®nanã‚’è¿”ã™
    if batch_neuron_values.shape[0] <= 1:
        return np.full(batch_neuron_values.shape[1], np.nan)
    neuron_cov = np.cov(batch_neuron_values, rowvar=False) # (num_neurons_of_tgt_layer, num_neurons_of_tgt_layer)
    if abs:
        # adding covariances may cancel the effect, so take absolute value
        neuron_cov = np.abs(neuron_cov)
        num_neg = np.sum(neuron_cov < 0) # ãƒã‚¤ãƒŠã‚¹è¦ç´ ã®æ•°ã‚’å–å¾—
        assert num_neg == 0, f"Error: {num_neg} negative elements in neuron_cov"
    # ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³åˆ†æ•£å…±åˆ†æ•£è¡Œåˆ—ã®å¯¾è§’æˆåˆ† = å„ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®åˆ†æ•£ ã‚’å–å¾—
    neuron_var = np.diag(neuron_cov)
    # neuron_covã®å„è¡Œã®å’Œ
    neuron_cov_sum = np.nansum(neuron_cov, axis=0) # è‡ªåˆ†ã®åˆ†æ•£ + (ä»–ã®å…±åˆ†æ•£ã®ç·å’Œ)
    # ä»–ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¨ã®å…±åˆ†æ•£ã®å¹³å‡
    if covavg:
        cov_term = (neuron_cov_sum - neuron_var) / (neuron_cov_sum.shape[0] - 1)
    else:
        cov_term = neuron_cov_sum - neuron_var
    
    # vscoreã‚’è¨ˆç®—
    vscore = neuron_var + cov_term # (num_neurons_of_tgt_layer,)
    # vscoreã®æœ€å°ã¨æœ€å¤§ã‚’è¡¨ç¤º
    print(f"vscore min: {np.min(vscore)}, max: {np.max(vscore)}")
    return vscore

def localize_neurons(vscore_before_dir, vscore_dir, vscore_after_dir, tgt_layer, n, tgt_split="repair", misclf_pair=None, tgt_label=None, fpfn=None, rank_type="abs"):
    vmap_dic = defaultdict(np.array)
    for cor_mis in ["cor", "mis"]:
        ds_type = f"ori_{tgt_split}"
        # vscore_save_pathã®è¨­å®š
        vscore_save_path = os.path.join(vscore_dir, f"vscore_l1tol12_all_label_{ds_type}_{cor_mis}.npy")
        if misclf_pair is not None and cor_mis == "mis":
            # misclf_pairãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ï¼Œãã®å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’å–å¾—
            assert len(misclf_pair) == 2, f"Error: {misclf_pair}"
            slabel, tlabel = misclf_pair
            vscore_save_path = os.path.join(vscore_dir, f"vscore_l1tol12_{slabel}to{tlabel}_{ds_type}_{cor_mis}.npy")
        if tgt_label is not None and cor_mis == "mis":
            # tgt_labelãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ï¼Œãã®å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’å–å¾—
            vscore_save_path = os.path.join(vscore_dir, f"vscore_l1tol12_{tgt_label}_{ds_type}_{cor_mis}.npy")
            if fpfn is not None:
                vscore_save_path = os.path.join(vscore_dir, f"vscore_l1tol12_{tgt_label}_{ds_type}_{fpfn}_{cor_mis}.npy")
        # vscoreã‚’èª­ã¿è¾¼ã‚€
        vscores = np.load(vscore_save_path)
        vmap_dic[cor_mis] = vscores.T
    vmap_cor = vmap_dic["cor"]
    vmap_mis = vmap_dic["mis"]
    vmap_diff = vmap_cor - vmap_mis
    # vmap_diff[:, tgt_layer]ã®çµ¶å¯¾å€¤ã®ä¸Šä½nå€‹ã‚’å–å¾—
    vmap_diff_abs = np.abs(vmap_diff[:, tgt_layer])
    if isinstance(n, int):
        top_idx = np.argsort(vmap_diff_abs)[::-1][:n] # top_idx[k] = vmap_diff_absã®ä¸­ã§kç•ªç›®ã«å¤§ãã„å€¤ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    elif isinstance(n, float):
        assert n <= 1, f"Error: {n}"
        num_neurons = vmap_diff_abs.shape[0]
        top_idx = np.argsort(vmap_diff_abs)[::-1][:int(num_neurons * n)] # top_idx[k] = vmap_diff_absã®ä¸­ã§kç•ªç›®ã«å¤§ãã„å€¤ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    # top_idx[k]ã®é †ä½ãŒkã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
    for r, ti in enumerate(top_idx):
        # print(r, ti, vmap_diff_abs[ti])
        assert return_rank(vmap_diff_abs, ti) == r, f"Error: {ti}, {r}"
    places_to_fix = [[tgt_layer, pos] for pos in top_idx]
    # vmap_diff[:, tgt_layer]ã‹ã‚‰conditionã«åˆã†ã‚‚ã®ã ã‘å–ã‚Šå‡ºã™
    tgt_vdiff = vmap_diff[top_idx, tgt_layer]
    return places_to_fix, tgt_vdiff

def localize_neurons_random(vscore_before_dir, vscore_dir, vscore_after_dir, tgt_layer, n, tgt_split="repair", misclf_pair=None, tgt_label=None, fpfn=None, rank_type="abs"):
    def _get_vscore_shape(vscore_dir):
        for cor_mis in ["cor", "mis"]:
            ds_type = f"ori_{tgt_split}"
            vscore_save_path = os.path.join(vscore_dir, f"vscore_l1tol12_all_label_{ds_type}_{cor_mis}.npy")
            if misclf_pair is not None and cor_mis == "mis":
                # misclf_pairãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ï¼Œãã®å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’å–å¾—
                assert len(misclf_pair) == 2, f"Error: {misclf_pair}"
                slabel, tlabel = misclf_pair
                vscore_save_path = os.path.join(vscore_dir, f"vscore_l1tol12_{slabel}to{tlabel}_{ds_type}_{cor_mis}.npy")
            if tgt_label is not None and cor_mis == "mis":
                # tgt_labelãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ï¼Œãã®å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’å–å¾—
                vscore_save_path = os.path.join(vscore_dir, f"vscore_l1tol12_{tgt_label}_{ds_type}_{cor_mis}.npy")
                if fpfn is not None:
                    vscore_save_path = os.path.join(vscore_dir, f"vscore_l1tol12_{tgt_label}_{ds_type}_{fpfn}_{cor_mis}.npy")
            vscores = np.load(vscore_save_path)
            return vscores.shape
    vscore_shape = _get_vscore_shape(vscore_dir)
    num_neurons = vscore_shape[1]
    # ãƒ©ãƒ³ãƒ€ãƒ ã«num_neuronså€‹ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‹ã‚‰nå€‹ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’é¸ã¶
    top_idx = np.random.choice(num_neurons, n, replace=False)
    places_to_fix = [[tgt_layer, pos] for pos in top_idx]
    return places_to_fix, None

def rank_descending(x):
    # x ã‚’é™é †ã«ä¸¦ã¹æ›¿ãˆã‚‹ãŸã‚ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
    sorted_indices = np.argsort(x)[::-1]
    # é †ä½ç”¨ã®ç©ºã®é…åˆ—ã‚’æº–å‚™
    ranks = np.empty_like(sorted_indices)
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½¿ã£ã¦é †ä½ã‚’è¨­å®š
    ranks[sorted_indices] = np.arange(len(x))
    return ranks

def return_rank(x, i, order="desc"):
    # x[i] ã®é †ä½ã‚’è¿”ã™
    if order == "desc":
        return np.argsort(x)[::-1].tolist().index(i)
    elif order == "asc":
        return np.argsort(x).tolist().index(i)
    else:
        raise NotImplementedError

def localize_neurons_with_mean_activation(vscore_before_dir, vscore_dir, vscore_after_dir, tgt_layer, n, intermediate_states, tgt_mis_indices, tgt_split="repair", misclf_pair=None, tgt_label=None, fpfn=None, corruption_type=None, rank_type="abs", alpha=None, return_all_neuron_score=False, vscore_abs=False, covavg=True, vscore_cor_dir=None, return_before_norm=False):
    vmap_dic = defaultdict(np.array)
    # abs, covavg (vscoreè¨ˆç®—ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³) ã«ã‚ˆã£ã¦ãƒ•ã‚¡ã‚¤ãƒ«åãŒé•ã†
    vscore_path_prefix = ("vscore_abs" if vscore_abs else "vscore") + ("_covavg" if covavg else "")
    for cor_mis in ["cor", "mis"]:
        ds_type = f"ori_{tgt_split}"
        # vscore_save_pathã®è¨­å®š
        vscore_save_path = os.path.join(vscore_dir, f"{vscore_path_prefix}_l1tol12_all_label_{ds_type}_{cor_mis}.npy")
        if cor_mis == "mis":
            if misclf_pair is not None:
                # misclf_pairãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ï¼Œãã®å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’å–å¾—
                assert len(misclf_pair) == 2, f"Error: {misclf_pair}"
                slabel, tlabel = misclf_pair
                vscore_save_path = os.path.join(vscore_dir, f"{vscore_path_prefix}_l1tol12_{slabel}to{tlabel}_{ds_type}_mis.npy")
            if tgt_label is not None:
                # tgt_labelãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ï¼Œãã®å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’å–å¾—
                vscore_save_path = os.path.join(vscore_dir, f"{vscore_path_prefix}_l1tol12_{tgt_label}_{ds_type}_mis.npy")
                if fpfn is not None:
                    vscore_save_path = os.path.join(vscore_dir, f"{vscore_path_prefix}_l1tol12_{tgt_label}_{ds_type}_{fpfn}_mis.npy")
            if corruption_type is not None:
                # misclf_pair, tgt_label, fpfnãŒå…¨éƒ¨Noneã§ã‚ã‚‹ã“ã¨ã‚’ä¿è¨¼
                assert misclf_pair is None, f"Error: {misclf_pair}"
                assert tgt_label is None, f"Error: {tgt_label}"
                assert fpfn is None, f"Error: {fpfn}"
                vscore_save_path = os.path.join(vscore_dir, f"{vscore_path_prefix}_l1tol12_{tgt_label}_{corruption_type}_mis.npy")
        elif cor_mis == "cor":
            if misclf_pair is not None:
                label_str = f"label_{misclf_pair[1]}" # æ­£è§£ãƒ©ãƒ™ãƒ«ã«åˆã‚ã›ãŸã„
            else:
                assert tgt_label is not None, f"Error: {tgt_label}"
                if fpfn == "fn":
                    label_str = f"label_{tgt_label}" # ã¿ã®ãŒã•ã‚ŒãŸãƒ©ãƒ™ãƒ«ã«åˆã‚ã›ãŸã„
                else:
                    assert fpfn == "fp", f"Error: {fpfn}"
                    label_str = "all_label" # tgt_fpã®æ™‚ã ã‘æ­£è§£ãƒ©ãƒ™ãƒ«ãŒã•ã¾ã–ã¾ãªã®ã§å…¨ä½“ã®æ­£è§£ã‚’ä½¿ã†
            vscore_save_path = os.path.join(vscore_cor_dir, f"{vscore_path_prefix}_l1tol12_{label_str}_{ds_type}_cor.npy")
        # vscoreã‚’èª­ã¿è¾¼ã‚€
        print(f"vscore_save_path: {vscore_save_path}")
        vscores = np.load(vscore_save_path)
        vmap_dic[cor_mis] = vscores.T
    vmap_cor = vmap_dic["cor"]
    vmap_mis = vmap_dic["mis"]
    vmap_diff = vmap_cor - vmap_mis # shape: (num_neurons, num_layers) or (num_neurons,)
    # vmap_diffãŒ2æ¬¡å…ƒã®å ´åˆã¯ä»¥ä¸‹ã®å‡¦ç†
    if len(vmap_diff.shape) == 2:
        # vmap_diff[:, tgt_layer]ã®çµ¶å¯¾å€¤ã‚’vdiffã«é–¢ã™ã‚‹ã‚¹ã‚³ã‚¢
        vmap_diff_abs = np.abs(vmap_diff[:, tgt_layer]) # shape: (num_neurons,)
    elif len(vmap_diff.shape) == 1:
        vmap_diff_abs = np.abs(vmap_diff) # shape: (num_neurons,)
    # cache_statesã‹ã‚‰ä¸­é–“ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®å€¤ã‚’å–å¾—
    # print(intermediate_states.shape) # shape: (num_tgt_mis_samples, num_neurons)
    # æ´»æ€§åŒ–å¾Œå€¤ã®å…¨å¯¾è±¡èª¤åˆ†é¡ã‚µãƒ³ãƒ—ãƒ«ã«ã‚ãŸã£ã¦ã®å¹³å‡ã‚’mean_activationã«é–¢ã™ã‚‹ã‚¹ã‚³ã‚¢
    if tgt_mis_indices is None:
        # tgt_mis_indicesãŒNoneã®å ´åˆã¯ï¼Œå…¨ã¦ã®ä¸­é–“ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®å€¤ã‚’ä½¿ç”¨
        mean_activation = np.mean(intermediate_states, axis=0) # shape: (num_neurons,)
    else:
        mean_activation = np.mean(intermediate_states[tgt_mis_indices], axis=0) # shape: (num_neurons,)
    
    # min-maxæ­£è¦åŒ–ã™ã‚‹å‰ã®å€¤ã‚’å–ã£ã¦ãŠã
    _vmap_diff_abs = vmap_diff_abs.copy()
    _mean_activation = mean_activation.copy()
    
    # vmap_diff_absã¨mean_activationã‚’ãã‚Œãã‚Œmin-maxæ­£è¦åŒ–
    vmap_diff_abs = (vmap_diff_abs - np.min(vmap_diff_abs)) / (np.max(vmap_diff_abs) - np.min(vmap_diff_abs))
    mean_activation = (mean_activation - np.min(mean_activation)) / (np.max(mean_activation) - np.min(mean_activation))
    
    if alpha is None:
        # neuron_score ã¨ã—ã¦ï¼Œä¸Šã®2ã¤ã®ãƒ™ã‚¯ãƒˆãƒ«ã®è¦ç´ ã”ã¨ã®ç©ã‚’ä½¿ã†
        neuron_score = vmap_diff_abs * mean_activation # shape: (num_neurons,)
    else:
        # neuron_score ã¨ã—ã¦ï¼Œä¸Šã®2ã¤ã®ãƒ™ã‚¯ãƒˆãƒ«ã®é‡ã¿ä»˜ãå’Œ
        neuron_score = alpha * vmap_diff_abs + (1-alpha) * mean_activation # shape: (num_neurons,)
    
    if n is not None:
        # neuron_scoreã®ä¸Šä½nå€‹ã‚’å–å¾—
        if isinstance(n, int):
            top_idx = np.argsort(neuron_score)[::-1][:n] # top_idx[k] = vmap_diff_absã®ä¸­ã§kç•ªç›®ã«å¤§ãã„å€¤ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        elif isinstance(n, float):
            assert n <= 1, f"Error: {n}"
            top_idx = np.argsort(neuron_score)[::-1][:int(len(neuron_score) * n)] # top_idx[k] = vmap_diff_absã®ä¸­ã§kç•ªç›®ã«å¤§ãã„å€¤ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        else:
            print(n)
            raise NotImplementedError
        # top_idx[k]ã®é †ä½ãŒkã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        for r, ti in enumerate(top_idx):
            # print(r, ti, vmap_diff_abs[ti])
            assert return_rank(neuron_score, ti) == r, f"Error: {ti}, {r}"
        places_to_fix = [[tgt_layer, pos] for pos in top_idx]
        # vmap_diff[:, tgt_layer]ã‹ã‚‰conditionã«åˆã†ã‚‚ã®ã ã‘å–ã‚Šå‡ºã™
        tgt_neuron_score = neuron_score[top_idx]
    else: # n is Noneã®å ´åˆã¯ï¼Œé™é †ã‚½ãƒ¼ãƒˆã—ã¦ã‹ã‚‰å…¨ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®æƒ…å ±ã‚’è¿”ã™
        top_idx = np.argsort(neuron_score)[::-1]
        # top_idx[k]ã®é †ä½ãŒkã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        for r, ti in enumerate(top_idx):
            # print(r, ti, vmap_diff_abs[ti])
            assert return_rank(neuron_score, ti) == r, f"Error: {ti}, {r}"
        places_to_fix = [[tgt_layer, pos] for pos in top_idx]
        tgt_neuron_score = neuron_score[top_idx]
    if not return_all_neuron_score:
        # top_idxã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®ã‚¹ã‚³ã‚¢ã ã‘è¿”ã™
        return places_to_fix, tgt_neuron_score
    else:
        # å…¨ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®ã‚¹ã‚³ã‚¢ã‚’è¿”ã™
        if return_before_norm:
            return places_to_fix, tgt_neuron_score, neuron_score, _mean_activation, _vmap_diff_abs
        else:
            return places_to_fix, tgt_neuron_score, neuron_score

def localize_weights(vscore_before_dir, vscore_dir, vscore_after_dir, tgt_layer, n, tgt_split="repair", misclf_pair=None, tgt_label=None, fpfn=None, rank_type="abs"):

    vdiff_dic = defaultdict(defaultdict)
    # ä¸­é–“ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®å‰ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ï¼Œä¸­é–“ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ï¼Œä¸­é–“ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®å¾Œã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãã‚Œãã‚Œã®ç¹°ã‚Šè¿”ã—
    for ba, vscore_dir in zip(["before", "intermediate", "after"], [vscore_before_dir, vscore_dir, vscore_after_dir]):
        vdiff_dic[ba] = defaultdict(np.array)
        vmap_dic = defaultdict(np.array)
        # æ­£è§£ã¨ä¸æ­£è§£æ™‚ã®vscoreã‚’èª­ã¿è¾¼ã‚€
        for cor_mis in ["cor", "mis"]:
            vmap_dic[cor_mis] = defaultdict(np.array)
            ds_type = f"ori_{tgt_split}"
            vscore_save_path = os.path.join(vscore_dir, f"vscore_l1tol12_all_label_{ds_type}_{cor_mis}.npy")
            if misclf_pair is not None and cor_mis == "mis":
                # misclf_pairãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ï¼Œãã®å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’å–å¾—
                assert len(misclf_pair) == 2, f"Error: {misclf_pair}"
                slabel, tlabel = misclf_pair
                vscore_save_path = os.path.join(vscore_dir, f"vscore_l1tol12_{slabel}to{tlabel}_{ds_type}_{cor_mis}.npy")
            if tgt_label is not None and cor_mis == "mis":
                # tgt_labelãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ï¼Œãã®å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’å–å¾—
                vscore_save_path = os.path.join(vscore_dir, f"vscore_l1tol12_{tgt_label}_{ds_type}_{cor_mis}.npy")
                if fpfn is not None:
                    vscore_save_path = os.path.join(vscore_dir, f"vscore_l1tol12_{tgt_label}_{ds_type}_{fpfn}_{cor_mis}.npy")
            vscores = np.load(vscore_save_path)
            vmap_dic[cor_mis] = vscores.T
        vmap_cor = vmap_dic["cor"]
        vmap_mis = vmap_dic["mis"]
        # vdiffã¨ãã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’baã«ç´ã¥ã„ãŸè¾æ›¸ã«ä¿å­˜
        vmap_diff = vmap_cor - vmap_mis
        if rank_type == "abs":
            vdiff_dic[ba]["vdiff"] = np.abs(vmap_diff[:, tgt_layer])
            vdiff_dic[ba]["rank"] = rank_descending(vdiff_dic[ba]["vdiff"]) # çµ¶å¯¾å€¤ã®é™é †
            order = "desc"
        else:
            vdiff_dic[ba]["vdiff"] = vmap_diff[:, tgt_layer]
            if rank_type == "desc":
                vdiff_dic[ba]["rank"] = rank_descending(vdiff_dic[ba]["vdiff"]) # çµ¶å¯¾å€¤å–ã‚‹å‰ã®å€¤ã®å¤§ãã„é †
                order = "desc"
            elif rank_type == "asc":
                vdiff_dic[ba]["rank"] = rank_descending(- vdiff_dic[ba]["vdiff"]) # çµ¶å¯¾å€¤å–ã‚‹å‰ã®å€¤ã®å°ã•ã„é †
                order = "asc"
            else:
                raise NotImplementedError
        # vdiff_dic[ba]["vdiff"]ã®iç•ªç›®ã®å€¤ã®é †ä½ãŒvdiff_dic[ba]["rank"]ã®iç•ªç›®ã¨ç­‰ã—ã„ã“ã¨ã‚’ç¢ºèª
        for i, r in enumerate(vdiff_dic[ba]["rank"]):
            assert return_rank(vdiff_dic[ba]["vdiff"], i, order) == r, f"Error: {i}, {r}"
        # rankã®ãƒ¦ãƒ‹ãƒ¼ã‚¯æ€§ã®ç¢ºèªã®ãŸã‚ã®ãƒ—ãƒªãƒ³ãƒˆ
        # print(f"{len(set(vdiff_dic[ba]['rank']))} / {len(vdiff_dic[ba]['rank'])}")
        # print(f'({ba}) |vdiff| [min, max] = [{np.min(vdiff_dic[ba]["vdiff"])}, {np.max(vdiff_dic[ba]["vdiff"])}]')
    # before,afterã‹ã‚‰top nå€‹ãšã¤ï¼Œintermediateã‹ã‚‰top 4nå€‹ã‚’å–å¾—
    top_idx_dic = defaultdict(list)
    for ba, dic in vdiff_dic.items():
        if ba == "intermediate":
            topx = 4*n
        else:
            topx = n
        top_idx_dic[ba] = np.where(dic["rank"] < topx)[0]
        # print(f"{ba}: {top_idx_dic[ba]}")
    # before-intermediate, intermediate-afterã®ä¿®æ­£ç®‡æ‰€ã‚’è¿”ã™
    pos_before = np.array(list(product(top_idx_dic["intermediate"], top_idx_dic["before"])))
    pos_after = np.array(list(product(top_idx_dic["after"], top_idx_dic["intermediate"])))
    return pos_before, pos_after

def get_vscore_diff_and_sim(vscore_before_dir, vscore_dir, vscore_after_dir, tgt_split="repair", misclf_pair=None, tgt_label=None, fpfn=None):

    vdiff_dic = defaultdict(np.array)
    # ä¸­é–“ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®å‰ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ï¼Œä¸­é–“ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ï¼Œä¸­é–“ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®å¾Œã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãã‚Œãã‚Œã®ç¹°ã‚Šè¿”ã—
    for ba, vscore_dir in zip(["before", "intermediate", "after"], [vscore_before_dir, vscore_dir, vscore_after_dir]):
        vdiff_dic[ba] = defaultdict(np.array)
        vmap_dic = defaultdict(np.array)
        # æ­£è§£ã¨ä¸æ­£è§£æ™‚ã®vscoreã‚’èª­ã¿è¾¼ã‚€
        for cor_mis in ["cor", "mis"]:
            vmap_dic[cor_mis] = defaultdict(np.array)
            ds_type = f"ori_{tgt_split}"
            vscore_save_path = os.path.join(vscore_dir, f"vscore_l1tol12_all_label_{ds_type}_{cor_mis}.npy")
            if misclf_pair is not None and cor_mis == "mis":
                # misclf_pairãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ï¼Œãã®å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’å–å¾—
                assert len(misclf_pair) == 2, f"Error: {misclf_pair}"
                slabel, tlabel = misclf_pair
                vscore_save_path = os.path.join(vscore_dir, f"vscore_l1tol12_{slabel}to{tlabel}_{ds_type}_{cor_mis}.npy")
            if tgt_label is not None and cor_mis == "mis":
                # tgt_labelãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ï¼Œãã®å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’å–å¾—
                vscore_save_path = os.path.join(vscore_dir, f"vscore_l1tol12_{tgt_label}_{ds_type}_{cor_mis}.npy")
                if fpfn is not None:
                    vscore_save_path = os.path.join(vscore_dir, f"vscore_l1tol12_{tgt_label}_{ds_type}_{fpfn}_{cor_mis}.npy")
            print(f"vscore_save_path: {vscore_save_path}")
            vscores = np.load(vscore_save_path)
            vmap_dic[cor_mis] = vscores.T
        vmap_cor = vmap_dic["cor"]
        vmap_mis = vmap_dic["mis"]
        # vdiffã¨ãã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’baã«ç´ã¥ã„ãŸè¾æ›¸ã«ä¿å­˜
        vmap_diff = vmap_cor - vmap_mis
        vdiff_dic[ba]["vdiff"] = vmap_diff
        dot_products = np.sum(vmap_cor * vmap_mis, axis=0)
        a_norms = np.linalg.norm(vmap_cor, axis=0)
        b_norms = np.linalg.norm(vmap_mis, axis=0)
        cosine_similarity = dot_products / (a_norms * b_norms)
        vdiff_dic[ba]["cos_sim"] = cosine_similarity
    return vdiff_dic

def localize_weights_random(vscore_before_dir, vscore_dir, vscore_after_dir, tgt_layer, n, tgt_split="repair", misclf_pair=None, tgt_label=None, fpfn=None, rank_type=None):
    def _get_vscore_shape(vscore_dir):
        for cor_mis in ["cor", "mis"]:
            ds_type = f"ori_{tgt_split}"
            vscore_save_path = os.path.join(vscore_dir, f"vscore_l1tol12_all_label_{ds_type}_{cor_mis}.npy")
            if misclf_pair is not None and cor_mis == "mis":
                # misclf_pairãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ï¼Œãã®å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’å–å¾—
                assert len(misclf_pair) == 2, f"Error: {misclf_pair}"
                slabel, tlabel = misclf_pair
                vscore_save_path = os.path.join(vscore_dir, f"vscore_l1tol12_{slabel}to{tlabel}_{ds_type}_{cor_mis}.npy")
            if tgt_label is not None and cor_mis == "mis":
                # tgt_labelãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ï¼Œãã®å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’å–å¾—
                vscore_save_path = os.path.join(vscore_dir, f"vscore_l1tol12_{tgt_label}_{ds_type}_{cor_mis}.npy")
                if fpfn is not None:
                    vscore_save_path = os.path.join(vscore_dir, f"vscore_l1tol12_{tgt_label}_{ds_type}_{fpfn}_{cor_mis}.npy")
            vscores = np.load(vscore_save_path)
            return vscores.shape

    top_idx_dic = defaultdict(list)
    for ba, vscore_dir in zip(["before", "intermediate", "after"], [vscore_before_dir, vscore_dir, vscore_after_dir]):
        vscore_shape = _get_vscore_shape(vscore_dir)
        num_neurons = vscore_shape[1]
        # ãƒ©ãƒ³ãƒ€ãƒ ã«n ã‚‚ã—ãã¯ 4nå€‹ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’é¸ã¶
        if ba == "intermediate":
            topx = 4*n
        else:
            topx = n
        top_idx_dic[ba] = np.random.choice(num_neurons, topx, replace=False)
    # before-intermediate, intermediate-afterã®ä¿®æ­£ç®‡æ‰€ã‚’è¿”ã™
    pos_before = np.array(list(product(top_idx_dic["intermediate"], top_idx_dic["before"])))
    pos_after = np.array(list(product(top_idx_dic["after"], top_idx_dic["intermediate"])))
    return pos_before, pos_after

class ViTFromLastLayer(nn.Module):
    def __init__(self, base_model):
        super(ViTFromLastLayer, self).__init__()
        self.base_model = base_model
        self.base_model.eval()
        self.base_model_last_layer = self.base_model.vit.encoder.layer[-1]

    def forward(self, hidden_states_before_layernorm, tgt_pos=None, tmp_score=None,
        imp_pos=None, imp_op=None):
        layer_output = self.base_model_last_layer.layernorm_after(hidden_states_before_layernorm)
        layer_output = self.base_model_last_layer.intermediate(layer_output, tgt_pos=tgt_pos, tmp_score=tmp_score, imp_pos=imp_pos, imp_op=imp_op)
        layer_output = self.base_model_last_layer.output(layer_output, hidden_states_before_layernorm)
        sequence_output = self.base_model.vit.layernorm(layer_output)
        logits = self.base_model.classifier(sequence_output[:, 0, :])
        return logits
    
# def generate_random_positions(start_layer_idx, end_layer_idx, num_neurons, num_kn):
#     """
#     ãƒ©ãƒ³ãƒ€ãƒ ã«çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®ä½ç½® (start_layer_idxä»¥ä¸Šã‹ã¤end_layer_idx-1ä»¥ä¸‹ã®ãƒ¬ã‚¤ãƒ¤ç•ªå·, 0ä»¥ä¸Šnum_neuronsä»¥ä¸‹ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ç•ªå·) ã‚’é¸ã¶
#     """
#     kn_list = []
#     for _ in range(num_kn):
#         layer_idx = np.random.randint(start_layer_idx, end_layer_idx)
#         neuron_idx = np.random.randint(num_neurons)
#         kn_list.append([layer_idx, neuron_idx])
#     return kn_list

def get_misclf_info(pred_labels, true_labels, num_classes):
    # èª¤åˆ†é¡ã®æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
    mis_matrix = np.zeros((num_classes, num_classes), dtype=int)
    mis_indices = {i: {j: [] for j in range(num_classes) if i != j} for i in range(num_classes)}
    for idx, (pred, true) in enumerate(zip(pred_labels, true_labels)):
        if pred != true:
            mis_matrix[pred, true] += 1
            mis_indices[pred][true].append(idx)  # Track the indices where the misclassification occurred
    # èª¤åˆ†é¡ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ä½œæˆ
    mis_ranking = []
    for i in range(num_classes):
        for j in range(num_classes):
            if i != j:
                mis_ranking.append((i, j, mis_matrix[i, j]))
    mis_ranking.sort(key=lambda x: x[2], reverse=True)
    print("Top 10 misclassification:")
    for i, j, mis in mis_ranking[:10]:
        print(f"pred {i} -> true {j}: {mis} / {mis_matrix.sum()} = {100 * mis / mis_matrix.sum():.2f} %")

    # ã‚¯ãƒ©ã‚¹ã”ã¨ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’1ã¤ã®è¾æ›¸ã«ã¾ã¨ã‚ã‚‹
    met_dict = defaultdict(np.array)
    precision, recall, f1_metric = evaluate.load("precision"), evaluate.load("recall"), evaluate.load("f1")
    precisions = precision.compute(predictions=pred_labels, references=true_labels, average=None) # {"metric_name": ã‚¯ãƒ©ã‚¹ã”ã¨ã®metric valueã®array} ã®è¾æ›¸å½¢å¼
    recalls = recall.compute(predictions=pred_labels, references=true_labels, average=None)
    f1_scores = f1_metric.compute(predictions=pred_labels, references=true_labels, average=None)
    for met_item in [precisions, recalls, f1_scores]:
        met_dict.update(met_item)

    # metricã®æ‚ªã„é †ã«idxã¨metricã®ãƒšã‚¢ã‚’è¡¨ç¤º
    for metric in met_dict.keys():
        print(f"Top 10 worst {metric} scores:")
        met_ranking = sorted(enumerate(met_dict[metric]), key=lambda x: x[1])
        for idx, score in met_ranking[:10]:
            print(f"label: {idx}, {metric}: {score}")

    return mis_matrix, mis_ranking, mis_indices, met_dict

def src_tgt_selection(mis_ranking, mis_indices, tgt_rank):
    """
    src-tgtå‹ã®repairã‚’ã—ãŸã„å ´åˆã«ä½¿ã†
    src-tgtå‹ã®èª¤åˆ†é¡ã«ãŠã„ã¦ï¼Œtgt_rankç•ªç›®ã®èª¤åˆ†é¡æƒ…å ±ã‚’å–ã‚Šå‡ºã™ï¼
    å…·ä½“çš„ã«ã¯äºˆæ¸¬ãƒ©ãƒ™ãƒ«ï¼Œæ­£è§£ãƒ©ãƒ™ãƒ«ï¼Œè©²å½“ã‚µãƒ³ãƒ—ãƒ«ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–ã‚Šå‡ºã™ï¼
    """
    # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‹ã‚‰å¯¾è±¡ã®èª¤åˆ†é¡æƒ…å ±ã‚’å–ã‚Šå‡ºã™
    slabel, tlabel, mis_cnt = mis_ranking[tgt_rank-1]
    tgt_mis_indices = mis_indices[slabel][tlabel]
    return slabel, tlabel, np.array(tgt_mis_indices)

def tgt_selection(met_dict, mis_indices, tgt_rank, used_met="f1"):
    """
    tgtå‹ã®repairã‚’ã—ãŸã„å ´åˆã«ä½¿ã†
    tgtå‹ã®èª¤åˆ†é¡ã«ãŠã„ã¦ï¼Œtgt_rankç•ªç›®ã«used_metã®æ‚ªã„ãƒ©ãƒ™ãƒ«ã‚’ç‰¹å®šã—ï¼Œãã®æƒ…å ±ã‚’å–ã‚Šå‡ºã™ï¼
    å…·ä½“çš„ã«ã¯å¯¾è±¡ãƒ©ãƒ™ãƒ«ï¼Œè©²å½“ã‚µãƒ³ãƒ—ãƒ«ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–ã‚Šå‡ºã™ï¼
    """
    metrics = met_dict[used_met]
    num_labels = len(metrics)
    met_ranking = sorted(enumerate(metrics), key=lambda x: x[1])
    tgt_label = met_ranking[tgt_rank-1][0]
    tgt_mis_indices = []
    for pred_label in range(num_labels):
        for true_label in range(num_labels):
            # used_metã«ã‚ˆã£ã¦èª¤åˆ†é¡ã®å®šç¾©ã‚’å¤‰ãˆã‚‹
            if used_met == "f1": # false positive and false negative
                cond_fpfn = (pred_label == tgt_label or true_label == tgt_label)
            elif used_met == "precision": # false positive
                cond_fpfn = (pred_label == tgt_label)
            elif used_met == "recall": # false negative
                cond_fpfn = (true_label == tgt_label)
            # pred_label != true_labelãªã®ã§èª¤åˆ†é¡ã‚µãƒ³ãƒ—ãƒ«
            # pred_label == tgt_labelã¯False positive, true_label == tgt_labelã¯False negative
            if cond_fpfn and pred_label != true_label:
                tgt_mis_indices.extend(mis_indices[pred_label][true_label])
    return tgt_label, np.array(tgt_mis_indices)

def all_selection(mis_indices):
    """
    allå‹ã®repairã‚’ã™ã‚‹å ´åˆã«ä½¿ã†.
    mis_indices[i][j]ã«æ ¼ç´ã•ã‚Œã¦ã„ã‚‹ã™ã¹ã¦ã®ãƒªã‚¹ãƒˆã‚’1æ¬¡å…ƒã«ã—ã¦çµåˆã™ã‚‹.
    """
    tgt_mis_indices = []
    for mi in mis_indices.values():
        for mij in mi.values():
            if len(mij) > 0:
                tgt_mis_indices.extend(mij)
    return np.array(tgt_mis_indices)

def identfy_tgt_misclf(misclf_info_dir, tgt_split="repair", misclf_type="tgt", tgt_rank=1, fpfn=None):
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ãƒ­ãƒ¼ãƒ‰
    with open(os.path.join(misclf_info_dir, f"{tgt_split}_mis_indices.pkl"), "rb") as f:
        mis_indices = pickle.load(f)
    # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®ãƒ­ãƒ¼ãƒ‰
    with open(os.path.join(misclf_info_dir, f"{tgt_split}_mis_ranking.pkl"), "rb") as f:
        mis_ranking = pickle.load(f)
    # metrics dictã®ãƒ­ãƒ¼ãƒ‰
    with open(os.path.join(misclf_info_dir, f"{tgt_split}_met_dict.pkl"), "rb") as f:
        met_dict = pickle.load(f)
    if misclf_type == "src_tgt":
        slabel, tlabel, tgt_mis_indices = src_tgt_selection(mis_ranking, mis_indices, tgt_rank)
        misclf_pair = (slabel, tlabel)
        tgt_label = None
    elif misclf_type == "tgt":
        if fpfn is None:
            used_met = "f1"
        elif fpfn == "fp":
            used_met = "precision"
        elif fpfn == "fn":
            used_met = "recall"
        else:
            NotImplementedError, f"fpfn: {fpfn}"
        tlabel, tgt_mis_indices = tgt_selection(met_dict, mis_indices, tgt_rank, used_met=used_met)
        tgt_label = tlabel
        misclf_pair = None
    elif misclf_type == "all":
        tgt_mis_indices = all_selection(mis_indices)
        tgt_label = None
        misclf_pair = None
    else:
        NotImplementedError, f"misclf_type: {misclf_type}"
    return misclf_pair, tgt_label, tgt_mis_indices

def get_ori_model_predictions(pred_res_dir, labels, tgt_split="repair", misclf_type="tgt", tgt_label=None):
    """
    ã™ã§ã«pklã§ä¿å­˜ã•ã‚ŒãŸ, å¤ã„ãƒ¢ãƒ‡ãƒ«ã®tgt_splitã«å¯¾ã™ã‚‹äºˆæ¸¬çµæœã‚’å–å¾—ã™ã‚‹.
    """
    # original model ã® repair setã®å„ã‚µãƒ³ãƒ—ãƒ«ã«å¯¾ã™ã‚‹æ­£è§£/ä¸æ­£è§£ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
    with open(os.path.join(pred_res_dir, f"{tgt_split}_pred.pkl"), "rb") as f:
        pred_res = pickle.load(f)
    pred_logits = pred_res.predictions
    ori_pred_labels = np.argmax(pred_logits, axis=-1)
    is_correct = ori_pred_labels == labels[tgt_split]
    indices_to_correct = np.where(is_correct)[0]
    if misclf_type == "tgt":
        assert tgt_label is not None, f"tgt_label should be specified when misclf_type is tgt."
        # misclf_type == "tgt"ã®å ´åˆã¯ï¼Œtgt_labelã§æ­£è§£ã—ãŸã‚‚ã®ã ã‘ã‚’correctã¨ã—ã¦æ‰±ã†
        is_correct_tgt = is_correct & (labels[tgt_split] == tgt_label)
        indices_to_correct_tgt = np.where(is_correct_tgt)[0]
        # is_correctã®ãƒªã‚¹ãƒˆã‹ã‚‰is_correct_for_tgtã‚’é™¤å¤–ã—ãŸã‚‚ã®ã‚’is_correctã«ã™ã‚‹
        is_correct_others = is_correct & (labels[tgt_split] != tgt_label)
        indices_to_correct_others = np.where(is_correct_others)[0]
        return ori_pred_labels, is_correct_tgt, indices_to_correct_tgt, is_correct_others, indices_to_correct_others
    return ori_pred_labels, is_correct, indices_to_correct

def get_new_model_predictions(vit_from_last_layer, batch_hs_before_layernorm, batch_labels, tgt_pos=0):
    """
    ã¾ã ä¿å­˜ã•ã‚Œã¦ã„ãªã„, æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã®tgt_splitã«å¯¾ã™ã‚‹äºˆæ¸¬çµæœã‚’å–å¾—ã™ã‚‹.
    """
    all_pred_labels = []
    all_true_labels = []
    for cache_state, y in zip(batch_hs_before_layernorm, batch_labels):
        logits = vit_from_last_layer(hidden_states_before_layernorm=cache_state, tgt_pos=tgt_pos)
        # å‡ºåŠ›ã•ã‚ŒãŸlogitsã‚’ç¢ºç‡ã«å¤‰æ›
        proba = torch.nn.functional.softmax(logits, dim=-1)
        pred_label = torch.argmax(proba, dim=-1)
        for pl, tl in zip(pred_label, y):
            all_pred_labels.append(pl.item())
            all_true_labels.append(tl)
    all_pred_labels = np.array(all_pred_labels)
    all_true_labels = np.array(all_true_labels)
    return all_pred_labels, all_true_labels

def get_batched_hs(hs_save_path, batch_size, tgt_indices=None, device=torch.device("cuda"), hs=None):
    if hs is None:
        hs_before_layernorm = torch.from_numpy(np.load(hs_save_path, mmap_mode="r")).to(device)
    else:
        hs_before_layernorm = hs
    if tgt_indices is not None:
        # ä½¿ã†ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«å¯¾ã™ã‚‹çŠ¶æ…‹ã ã‘ã‚’å–ã‚Šå‡ºã™
        hs_before_layernorm_tgt = hs_before_layernorm[tgt_indices]
    else:
        hs_before_layernorm_tgt = hs_before_layernorm
    num_batches = (hs_before_layernorm_tgt.shape[0] + batch_size - 1) // batch_size  # ãƒãƒƒãƒã®æ•°ã‚’è¨ˆç®— (æœ€å¾Œã®ä¸­é€”åŠç«¯ãªãƒãƒƒãƒã‚‚ä½¿ã„ãŸã„ã®ã§ï¼Œåˆ‡ã‚Šä¸Šã’)
    batch_hs_before_layernorm_tgt = np.array_split(hs_before_layernorm_tgt, num_batches)
    return batch_hs_before_layernorm_tgt

def get_batched_labels(labels, batch_size, tgt_indices=None):
    if tgt_indices is not None:
        labels_tgt = labels[tgt_indices]
    else:
        labels_tgt = labels
    num_batches = (len(labels_tgt) + batch_size - 1) // batch_size  # ãƒãƒƒãƒã®æ•°ã‚’è¨ˆç®— (æœ€å¾Œã®ä¸­é€”åŠç«¯ãªãƒãƒƒãƒã‚‚ä½¿ã„ãŸã„ã®ã§ï¼Œåˆ‡ã‚Šä¸Šã’)
    batch_labels = np.array_split(labels_tgt, num_batches)
    return batch_labels

def sample_from_correct_samples(num_sampled_from_correct, indices_to_correct):
    if num_sampled_from_correct < len(indices_to_correct):
        sampled_indices_to_correct = np.random.choice(indices_to_correct, num_sampled_from_correct, replace=False)
    else:
        sampled_indices_to_correct = indices_to_correct
    return sampled_indices_to_correct

# def sample_true_positive_indices_per_class(num_sampled_from_correct, indices_to_correct, ori_pred_labels):
#     # äºˆæ¸¬ãƒ©ãƒ™ãƒ«ã”ã¨ã«True Positiveã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
#     true_positive_indices_per_class = defaultdict(list)
#     for i, pred_label in enumerate(ori_pred_labels):
#         if i in indices_to_correct:
#             true_positive_indices_per_class[pred_label].append(i)
#     # true_positive_indices_per_classã®å„ã‚¯ãƒ©ã‚¹ã®ãƒªã‚¹ãƒˆã®é•·ã•ã‚’è¡¨ç¤º
#     tot = 0
#     for label, idx_list in true_positive_indices_per_class.items():
#         print(f"label: {label}, num_samples: {len(idx_list)}, num_sampled: {num_sampled_from_correct // len(idx_list)}")
#         tot += num_sampled_from_correct // len(idx_list)
#     print(f"total num_samples: {tot}")
#     exit()
#     # num_sampled_from_correctã¯åˆè¨ˆã®ã‚µãƒ³ãƒ—ãƒ«æ•°ãªã®ã§num_classã§å‰²ã‚‹
#     num_sampled_from_correct_per_class = num_sampled_from_correct // len(true_positive_indices_per_class.keys())
#     # å„ã‚¯ãƒ©ã‚¹ã‹ã‚‰num_sampled_from_correctå€‹ãšã¤ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
#     sampled_indices = []
#     for label, idx_list in true_positive_indices_per_class.items():
#         sampled_indices += np.random.choice(idx_list, num_sampled_from_correct_per_class, replace=False).tolist()
#     return np.array(sampled_indices)


def sample_true_positive_indices_per_class(
    num_sampled_from_correct,
    indices_to_correct,
    ori_pred_labels,
):
    """
    True Positive ã‹ã‚‰ã‚¯ãƒ©ã‚¹åˆ†å¸ƒã«æ¯”ä¾‹ã—ã¦ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ç„¡ä½œç‚ºæŠ½å‡ºã™ã‚‹ã€‚

    Parameters
    ----------
    num_sampled_from_correct : int
        å–ã‚Šå‡ºã—ãŸã„ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ç·æ•° (ä¸Šé™)ã€‚
    indices_to_correct : Iterable[int]
        True Positive ã¨ãªã£ã¦ã„ã‚‹å…ƒãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹é›†åˆã€‚
    ori_pred_labels : Sequence[int]
        å„ã‚µãƒ³ãƒ—ãƒ«ã®äºˆæ¸¬ãƒ©ãƒ™ãƒ«ã€‚

    Returns
    -------
    np.ndarray
        æŠ½å‡ºã•ã‚ŒãŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ (dtype=int)ã€‚
    """
    rng = np.random.default_rng()

    # --- 1) ã‚¯ãƒ©ã‚¹ã”ã¨ã® TP ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’åé›† -----------------------------
    tp_per_class = defaultdict(list)
    indices_to_correct = set(indices_to_correct)  # O(1) å‚ç…§ç”¨ã«ã‚»ãƒƒãƒˆåŒ–
    for idx, pred_label in enumerate(ori_pred_labels):
        if idx in indices_to_correct:
            tp_per_class[pred_label].append(idx)

    if not tp_per_class:
        return np.array([], dtype=int)

    # --- 2) æŠ½å‡ºæ•°ã‚’ã‚¯ãƒ©ã‚¹åˆ†å¸ƒã«æ¯”ä¾‹é…åˆ† -----------------------------------
    counts = {lbl: len(lst) for lbl, lst in tp_per_class.items()}
    total_tp = sum(counts.values())
    num_to_sample = min(num_sampled_from_correct, total_tp)
    print(f"sampling {num_to_sample} samples from {total_tp} samples...")

    # åˆæœŸå‰²å½“ï¼ˆåºŠé–¢æ•°ã§ä¸¸ã‚ã‚‹ï¼‰
    alloc = {lbl: (num_to_sample * cnt) // total_tp for lbl, cnt in counts.items()}
    # ã“ã®æ®µéšã§ã¯å‰²å½“ã®åˆè¨ˆãŒ num_to_sample ã‚ˆã‚Šå°ã•ã„ã“ã¨ãŒã‚ã‚‹
    assert sum(alloc.values()) <= num_to_sample, f"alloc: {alloc}, num_to_sample: {num_to_sample}, total_tp: {total_tp}"

    # --- 3) ç«¯æ•°ã‚’ä½™åŠ›ã®ã‚ã‚‹ã‚¯ãƒ©ã‚¹ã¸ãƒ©ãƒ³ãƒ€ãƒ ã«é…åˆ† --------------------------
    remaining = num_to_sample - sum(alloc.values())
    leftover = {lbl: counts[lbl] - alloc[lbl] for lbl in counts}
    
    while remaining > 0:
        # ã¾ã å–ã‚Šå‡ºã›ã‚‹ã‚¯ãƒ©ã‚¹ã‚’å€™è£œã«
        candidates = [lbl for lbl, cap in leftover.items() if cap > 0]
        if not candidates:
            break  # å¿µã®ãŸã‚
        # ä½™åŠ›ã«æ¯”ä¾‹ã—ã¦ç¢ºç‡ä»˜ã‘
        probs = np.array([leftover[lbl] for lbl in candidates], dtype=float)
        probs /= probs.sum()
        chosen = rng.choice(candidates, p=probs)
        alloc[chosen] += 1
        leftover[chosen] -= 1
        remaining -= 1
    # ã“ã®æ®µéšã§ã¯å‰²å½“ã®åˆè¨ˆãŒ num_to_sample ã¨ç­‰ã—ããªã„ã¨ãŠã‹ã—ã„
    assert sum(alloc.values()) == num_to_sample, f"alloc: {alloc}, num_to_sample: {num_to_sample}, total_tp: {total_tp}"

    # --- 4) ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° ----------------------------------------------------
    sampled = []
    for lbl, k in alloc.items():
        if k > 0:
            sampled.extend(rng.choice(tp_per_class[lbl], k, replace=False).tolist())
    assert len(sampled) == num_to_sample, f"len(sampled): {len(sampled)}, num_to_sample: {num_to_sample}, total_tp: {total_tp}"
    # sampledã®å„ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒæ­£è§£ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«å«ã¾ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ä¿è¨¼
    for idx in sampled:
        assert idx in indices_to_correct, f"Error: {idx} not in indices_to_correct"
    return np.array(sampled, dtype=int)

def maybe_initialize_repair_weights_(model, missing_keys):
    if any("intermediate.repair.weight" in key for key in missing_keys):
        print("ğŸ› ï¸ Initializing intermediate.repair.weight as identity matrix (for missing weights)")
        with torch.no_grad():
            for layer in model.vit.encoder.layer:
                W = layer.intermediate.repair.weight
                W.copy_(torch.eye(W.shape[0], device=W.device))
                W.requires_grad = False
    return model

class WeightedTrainer(Trainer):
    def __init__(self, *args, alpha=0.5, **kwargs):
        super().__init__(*args, **kwargs)
        self.alpha = alpha # æ­£è§£/ä¸æ­£è§£ã‚µãƒ³ãƒ—ãƒ«ã¸ã®ãƒ­ã‚¹è¨ˆç®—ã«ãŠã‘ã‚‹é‡ã¿
        assert 0 <= alpha <= 1, f"alpha must be in [0, 1], but got {alpha}"
    def compute_loss(self, model, inputs, return_outputs=False):
        # NOTE: ã“ã®é–¢æ•°ã¯1ãƒãƒƒãƒã«å¯¾ã™ã‚‹ãƒ­ã‚¹ã®è¨ˆç®—
        labels = inputs.get("labels")
        outputs = model(**inputs)
        logits = outputs.get("logits")

        loss_fct = torch.nn.CrossEntropyLoss(reduction="none")
        loss_per_sample = loss_fct(logits, labels) # (ãƒãƒƒãƒã‚µã‚¤ã‚º, )
        
        # ğŸ” äºˆæ¸¬ãƒ©ãƒ™ãƒ« vs æ­£è§£ãƒ©ãƒ™ãƒ«ã‹ã‚‰æˆå¦ã‚’è¨ˆç®—
        pred_labels = torch.argmax(logits, dim=1)
        # ãƒãƒƒãƒã”ã¨ã®æ­£è§£/ä¸æ­£è§£ã«ã‚ˆã£ã¦ãƒ­ã‚¹ã«ç•°ãªã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’ã‹ã‘ã‚‹
        is_correct = (pred_labels == labels).to(dtype=torch.float32)
        # ã‚¹ã‚³ã‚¢ã®å®šç¾©
        score = torch.where(
            is_correct == 1,
            torch.ones_like(loss_per_sample),                      # æ­£è§£ãªã‚‰1
            1.0 / (loss_per_sample + 1.0)                 # ä¸æ­£è§£ãªã‚‰ 1 / (Loss + 1)
        )
        # print(f"score: {score}")
        
        device = logits.device
        n_correct_batch = max((is_correct == 1).sum().item(), 1)
        n_incorrect_batch = max((is_correct == 0).sum().item(), 1)

        # alphaã‚’ä½¿ã£ã¦é‡ã¿ã‚’èª¿æ•´
        sample_weights = torch.where(
            is_correct == 1,
            self.alpha / n_correct_batch,
            (1 - self.alpha) / n_incorrect_batch
        ).to(device)
        
        # print(f"weighted score: {score * sample_weights}")
        loss = - (score * sample_weights).sum()
        # print(f"loss: {loss}")

        return (loss, outputs) if return_outputs else loss