これに関するrepairの実験は全て `exp-repair-3-{実験サブID}` という形式でレポジトリに対応させる．
スクリプトのファイル名は `exp-repair-3-{実験サブID}-{スクリプトID}.py` とする．
これらのTODOは [[20250514亀井先生mtg]] を受けてまとめたもの．
# `exp-repair-3-1` (Arachne)
## 目的
Arachneのオリジナルの手法を適用する．
`exp-repair-2` までは重みの数を指定しないといけなかった．しかしオリジナルのArachneはFIとBIのパレート最適を取るのでそれに合わせる．
他の手法（RandomやVscoreベース）を適用する時はArachne適用時に特定された重み数の平均 $N_{avg}$ を実験設定の1つとする．
## ステップ
### ステップ1：FLの変更
- FIとBIをもとに重みを特定する処理を，FIとBIの平均ではなくパレートフロントにするよう変更する
- 重みの位置情報はファイル名でparetoとわかるようにする
### ステップ2：Arachneのsearchフェーズ実行
 - スクリプトはほぼ変わらないはず．重みの位置情報ファイルのロード先が変わるだけなので．
 - $\alpha$ の値はArachneの原論文と同じ10に限る．
	 - Arachneの式から，Inegへのスコアの重みがIposへの重みの10倍ということになる．
	 - 我々は合計1になる重みつき平均にしたい（見た目的に）ので，Inegへの重み=10/11, Iposへの重み=1/11 ということになる．これでもInegを10倍重視しているという点は同じ．
	 - 他のRQで $\alpha$ の影響を調べるようにする．
 - 使うデータセットの分け方について
	 - Repair実行に使うデータセット：FLと同じもの（FLの続きという体なので）
	 - Repairの評価に使うデータセット：test set（Repairと同じではダメ）
### ステップ3：テストセットで評価してデータ記録

# `exp-repair-3-2` (Random, VRepair)
## 目的
変更する重み数を $N_{avg}$ にしてRandomとVRepairを適用する．
Arachneとの比較をより公平に行うため．
## ステップ
基本的にArachneと同じ．

### ステップ1：FLの変更
- 重み数を $N_{avg}$ にする以外はこれまで同様．
- 重み数のパラメータをコード中で変えられるようにするだけ．
### ステップ2：Repair実行
- $\alpha$ の値はArachneの原論文と同じ10に限る．違う値に関しては別のRQで調べる．
### ステップ3：テストセットで評価してデータ記録

# [保留] `exp-repair-3-3` (LoRA)
## 目的
これまでの手法とは別のアプローチとして，PEFT的なアプローチを試みる．
LoRAはPEFT手法の中でもシンプルなもの．
Huggingfaceの学習の仕組みがそのまま使えるのでより高速化できるのでは？
しかし，実験設定として重み数をコントロールできるか不明なので一旦保留．`exp-repair-3-2` まで終わったら考える．
- LoRAの場合，変更される重み数は$2 r D_{hidden}$ となる ($r$はLoRAで縮小するランク数，$D_{hidden}$は隠れ状態の次元数．)
- これを $N_{avg}$ に合わせることができるのか？これが少なすぎたら無理なので別の実験ということになる．
## ステップ
