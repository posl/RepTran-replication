これに関するrepairの実験は全て `exp-repair-3-{実験サブID}` という形式でレポジトリに対応させる．
スクリプトのファイル名は `exp-repair-3-{実験サブID}-{スクリプトID}.py` とする．
これらのTODOは [[20250514亀井先生mtg]] を受けてまとめたもの．

> [!NOTE] このページでタスク管理風なこともしたい．
> 🥚 : 未着手
> 🏃 : 実行中
> 🏝️ : 実装は終わって実行待ち
> ✅ : 完了


# `exp-repair-3-1` (Arachne)
## 目的
Arachneのオリジナルの手法を適用する．
`exp-repair-2` までは重みの数を指定しないといけなかった．しかしオリジナルのArachneはFIとBIのパレート最適を取るのでそれに合わせる．
他の手法（RandomやVscoreベース）を適用する時はArachne適用時に特定された重み数の平均 $N_{avg}$ を実験設定の1つとする．
## ステップ
### ステップ1：FLの変更 ✅
- FIとBIをもとに重みを特定する処理を，FIとBIの平均ではなくパレートフロントにするよう変更する
- 重みの位置情報はファイル名でparetoとわかるようにする
- 該当スクリプト: `exp-repair-3-1-1.py`
- また，平均重み数は11.4個くらいであった（`exp-repair-3-1-4.ipynb` で集計した）
### ステップ2：Arachneのsearchフェーズ実行 ✅
 - スクリプトはほぼ変わらないはず．重みの位置情報ファイルのロード先が変わるだけなので．
 - $\alpha$ の値はArachneの原論文と同じ10に限る．
	 - Arachneの式から，Inegへのスコアの重みがIposへの重みの10倍ということになる．
	 - 我々は合計1になる重みつき平均にしたい（見た目的に）ので，Inegへの重み=10/11, Iposへの重み=1/11 ということになる．これでもInegを10倍重視しているという点は同じ．
	 - 他のRQで $\alpha$ の影響を調べるようにする．
 - 使うデータセットの分け方について
	 - Repair実行に使うデータセット：FLと同じもの（FLの続きという体なので）
	 - Repairの評価に使うデータセット：test set（Repairと同じではダメ）
 - Repairのrun数 = 対象の誤分類ベンチマーク9 x 実行の繰り返し 5 = 45回
	 - 大体1回のrunで400秒くらいなので，400sec x 45 = 5時間くらい．
 - 該当スクリプト: `exp-repair-3-1-2.py` (メイン処理の定義), `exp-repair-3-1-3.py` (メイン処理をいろんな設定で呼び出して実行)
### ステップ3：テストセットで評価してデータ記録 : ✅
- ステップ2で得られたrepaired patchesをモデルに適用して，テストデータに対して性能を評価する．
- 該当スクリプト: `exp-repair-3-1-5.py` (メイン処理の定義), `exp-repair-3-1-6.py` (メイン処理をいろんな設定で呼び出して実行)
### ステップ4：記録したデータを図表にまとめて可視化 ✅
- 表のフォーマット ([スプレッドシートにまとめた](https://docs.google.com/spreadsheets/d/1uWHwtBQAfbPHlw3VoTmLFNN3O2mkO-8lJFtGPBPLmtc/edit?gid=0#gid=0))
- ここで結果が微妙なことをRQ0として言う？
	- PureなArachneでは振る舞いを変えられない -> 新しい手法が必要！-> RQ1以降へ
- 該当スクリプト: `exp-repair-3-1-7.py` (結果の可視化)
## 結果
Pareto frontを取る場合は，重み数が少なすぎるのでほとんど振る舞いを変えない，という結果になりそう．

# `exp-repair-3-2` (Random, VRepair)
## 目的
変更する重み数を $N_{avg}$ にしてRandomとVRepairを適用する．
Arachneとの比較をより公平に行うため．
**本来我々の手法やランダムは重み数を調節できる．しかし，Arachneとの比較が不公平では？というツッコミに備えて，重み数をコントロールした実験をしておく．**
## ステップ
基本的にArachneと同じ．
3-1の実験の結果，Arachneで特定できた重み数は平均11.4だったので $N_{avg} = 11$ とする． 
### ステップ1：FLの変更 ✅
- 重み数を $N_{avg}$ にする以外はこれまで同様．
- 重み数のパラメータをコード中で変えられるようにするだけ．
- FLの手法：Arachneのスコアのパレートフロントではなく，平均にする．また，ニューロンスコアを考慮することでニューロン自体の影響を直接的に考慮できるようにする．
- 該当スクリプト: `exp-repair-3-2-1.py`
### ステップ2：Repair実行 (Vrepair: ✅, Random: ✅)
- $\alpha$ の値はArachneの原論文と同じ10に限る．違う値に関しては別のRQで調べる．
- ランダムの位置特定は3-2-2の中でやることにして位置の保存までやる．
- 該当スクリプト: `exp-repair-3-2-2.py` (メイン処理の定義), `exp-repair-3-2-3.py` (メイン処理をいろんな設定で呼び出して実行)
### ステップ3：テストセットで評価してデータ記録 (Vrepair: ✅, Random: ✅)
- ステップ2で得られたrepaired patchesをモデルに適用して，テストデータに対して性能を評価する．
- 該当スクリプト: `exp-repair-3-2-4.py` (メイン処理の定義), `exp-repair-3-2-5.py` (メイン処理をいろんな設定で呼び出して実行)
### ステップ4：記録したデータを図表にまとめて可視化 (Vrepair: ✅, Random: ✅)
- 該当スクリプト: `exp-repair-3-2-6.py`
## 結果
- Arachneは振る舞いの変更が少ない．Randomはもっとひどい．
- Oursはそこそこ副作用が増えるがちゃんとrepairもできる．
-> 限られたサンプル数においては我々が優れる
これFLの部分が違うだけなので，FLの評価とも取れるクネ？その意味ではRQ1にしたい．
重み数を変えた実験はRQ2でやる？