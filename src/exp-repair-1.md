# exp-repair-1: ViT for C100のリペア

# 実験方法
誤分類の種類; 5種類．
- all : 全ての誤分類
- src_tgt : 正解ラベルsrcをtgtというラベルと間違える (srcとtgtは異なるラベル)
- tgt_all : ラベルtgtが関与する全ての間違い (any-to-tgt or tgt-to-any)
- tgt_fp : ラベルtgtに関するfp (誤検知, any-to-tgt)
- tgt_fn : ラベルtgtに関するfn (見逃し, tgt-to-any)

それぞれの種類で特定した重みに対するDEを適用する．

# 必要なスクリプト
- `exp-repair-1-1.py`: DEアルゴリズムによるリペアを実行する. 007eが元々．
- `exp-repair-1-2.py`: いろんな設定でのイテレーションを作って， `exp-repair-1-1.py` のメイン関数を実行することを繰り返す. 007fが元々.
- `exp-repair-1-3.py`: 上のrepair結果をまとめる． 007gを参考にする．

# 評価方法
各誤分類の種類ごとに，RR (対象の誤分類のRR), BR (全体のBR) を出す？

# 実験結果

多分だけど，重み1.5% (73,728) 変更は多すぎるわ...
- allに対して，6480.857638246001 かかる．これを30reps x いろんな設定でやんないといけないのできつい

0.1%にしてみる?
- FLのコードを全部0.1%で再実行する必要がある
    - ours, random, blだけで良い
    - 重みの総数 = 768x3072x2 = 4,718,592 なので 0.1% をとると 4,718.592 ~ 4,718
    - これまでは特定する重みの数が 8x96x96 = 73,728 だったのでだいぶ減る
    - [exp-fl-1.md](/src/exp-fl-1.md) のやりかただとニューロン単位なので重みの数を直接コントロールできない．
        - hbef, haftのn=24 (hmidからは96) にすれば 8x24x24 = 4608 で一番近くなる
        - fl-1,2では↑でやって，それ以外の重みの数を直接コントロールできる手法 (fl-3) はちゃんとする．
    - ニューロンベースの選択の方は再実行いらないと思う．
        - 実質的な重み数 (768n) をコントロールできるように作られてない．
        - neuron単位のFLでn=24とすると実質重み数は 768x24 = 18,432 で増えちゃう．
        - [exp-fl-1.md](/src/exp-fl-1.md) の768x = 8y^2の整数解でいうと，(6, 24) に対応．つまりneuronレベルに対してはn=6としないといけない．
    - (n, w) = (6, 24), (24, 48), (96, 96) でやりたい．これは8w^2 = 768n (=実質重み数) をみたす (n, w) たち．
    - 変更重み数は3パターンで実験するということ．