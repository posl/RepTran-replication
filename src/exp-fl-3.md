# exp-fl-3: V-scoreベースFLの拡張
o1との議論を元にまとめる．

---

## 手法

本実験では、これまで V-score のみを使って行っていた Fault Localization (FL) を以下の2段階手法に拡張する。

1. **ニューロン特定フェーズ（V-score × Use\(_i\))**  
   - (a) $\Delta \mathrm{Vscore}_i = \mathrm{Vscore}_i(\text{誤例}) - \mathrm{Vscore}_i(\text{正例})$ が大きいニューロン
   - (b) 誤例サンプルにおける活性化率 $Use_i$ が高いニューロン．これは単純に誤分類サンプルに対する中間ニューロン値の平均でいい．正例との振る舞いの違いは(a)で考慮できているのでここでは考慮しなくていい？つまり，Use(-) - Use(+)とかはしなくていいと信じる．
   - 上記 (a) と (b) を組み合わせてスコア化し，**誤例に強く寄与するニューロン**を Top-K 個選出する。  
     - 例：$\mathrm{NeuronScore}_i = (\Delta \mathrm{Vscore}_i) \times \mathrm{Use}_i$

2. **重み特定フェーズ（Gradloss を用いた勾配ベース）**  
   - 上記で抽出したニューロン $i$ に関わる重み（入力側 $W_{\mathrm{bef}, i}$・出力側 $W_{\mathrm{aft}, i}$）を対象に，**誤例サンプルで逆伝播**し， $|\partial \mathcal{L} / \partial W|$ の大きい順にスコアを付与。  
   - これにより、「ニューロン $i$ の中でも特に誤分類ロスに強く影響する重み」= “修正効果が大きい” 重みを選定する。  
   - 最終的に上位 $M$ 個の重みインデックスを “Faulty 重み” として出力する。


---

## 必要なスクリプト
1. **2段階FLメインスクリプト**  
     1. `exp-fl-3-1.py`: (a) Vscore差 $\Delta \mathrm{Vscore}_i$，(b) $\text{Use}_i$ を読み込み，$\mathrm{NeuronScore}_i$ を計算 → 上位K個を抽出
        - cached_stateがあるので $\text{Use}_i$ は計算しなくていい．ロードするだけ．
        - ニューロン情報は追跡可能なファイル名で保存しておく．
        - ニューロンスコアが上位3%のニューロンだけ取り出して保存．
     2. `exp-fl-3-2.py`: そのニューロンに紐づく重みの勾配を誤例サンプルで逆伝播 → $\mathrm{WeightScore}_{i,j}$ を算出 → 上位M個の重みを最終故障リストに出力
        - `exp-fl-3-1.py`の結果をロード．そして前後の重みWbef(i,j), Waft(i,j)のロスの勾配を取得してランキングする．ここまで1回の順伝播と逆伝搬である．
        - 重みの数はexp-fl-1,2と同じ8x96x96とする (全重みの3%) ．比較できるように．
2. **評価スクリプト**  
   - `exp-fl-3-3.py`: Faulty重みに対してプルーニングを施し，exp-fl-1,2同様の図と検定を行う．

---

## 評価方法

1. **比較対象**  
   - **V-scoreのみ**（旧手法）  
   - **ランダム選択**（重み・ニューロンをランダムで特定）  
   - **Magnitude-based**（重みの絶対値が大きい順）  
   - **勾配ベースのみ**（全重みに対して $\|\partial \mathcal{L}/\partial W\|$ を計算し上位をFaultyとみなす）  

2. **修正方法**  
   - Faultyと判定した重みを再初期化 or プルーニング or 学習率を上げて部分再学習  
   - 修正後のモデルで**誤分類率がどれだけ下がるか**，全体精度がどれほど変化するかを比較

3. **指標**  
   - **$\Delta \mathrm{ErrorRate}$**: 修正前後の誤分類率の差  
   - **$\Delta \mathrm{Acc}$**: 全体精度の変化量  
   - **修正にかかる計算コスト**: 逆伝播の回数，修正後再学習のエポック数 など

---

## 期待する結果

- (A) **誤例に強く寄与するニューロン**をまず絞り込むため，計算効率が向上  
- (B) Use\(_i\) と勾配情報が入ることで，ランダムやV-scoreのみよりも**誤分類修正効果が高い重み**を特定可能  
- (C) 修正後の誤分類率低下量・精度改善量が，既存ベースラインを上回る  
- (D) モデルを壊しすぎずに，最小限の修正で誤分類を減少できる

---

## 実際の結果

- 実験中：  
  - 現在，誤例サンプルのバッチに対する勾配を取り，上記2段階FLを実装中．  
  - 今後の計画として，(1) 重み再初期化＆局所再学習，(2) プルーニング の2種類を試し，**どちらが誤分類率をより下げられるか**を比較する予定．  
- 完了後，結果として **(i) 誤分類改善率**，**(ii) 全体精度への影響度合い**，**(iii) 計算負荷**などをレポートし，V-scoreのみとの差異を明示する．