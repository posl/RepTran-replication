{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C10でFine-tuningしたViTモデルのフォワードパスを実行し，C10を予測する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライブラリのインポート\n",
    "transoformersに関しては，.vscode/setting.jsonのextrapathにパスを記載したらうまくインポートできた．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 17:07:30.567072: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-25 17:07:31.626156: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-04-25 17:07:31.626279: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-04-25 17:07:31.626290: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os, sys, math\n",
    "sys.path.append(\"../src\")\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from transformers import DefaultDataCollator, ViTForImageClassification, Trainer\n",
    "from utils.helper import get_device\n",
    "from utils.vit_util import processor, transforms, compute_metrics\n",
    "from utils.constant import ViTExperiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初期設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# デバイス (cuda, or cpu) の取得\n",
    "device = get_device()\n",
    "# datasetをロード (初回の読み込みだけやや時間かかる)\n",
    "dataset_dir = ViTExperiment.DATASET_DIR\n",
    "cifar10 = load_from_disk(os.path.join(dataset_dir, \"c10\"))\n",
    "# 読み込まれた時にリアルタイムで前処理を適用するようにする\n",
    "cifar10_preprocessed = cifar10.with_transform(transforms)\n",
    "# バッチごとの処理のためのdata_collator\n",
    "data_collator = DefaultDataCollator()\n",
    "# ラベルを示す文字列のlist\n",
    "labels = cifar10_preprocessed[\"train\"].features[\"label\"].names\n",
    "# pretrained modelのロード\n",
    "pretrained_dir = ViTExperiment.OUTPUT_DIR\n",
    "model = ViTForImageClassification.from_pretrained(pretrained_dir).to(device)\n",
    "model.eval()\n",
    "# 学習時の設定をロード\n",
    "training_args = torch.load(os.path.join(pretrained_dir, \"training_args.bin\"))\n",
    "# Trainerオブジェクトの作成\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=cifar10_preprocessed[\"train\"],\n",
    "    eval_dataset=cifar10_preprocessed[\"test\"],\n",
    "    tokenizer=processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推論の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.label_names=['labels']\n",
      "dict_keys(['pixel_values', 'labels'])\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.label_names=['labels']\n",
      "dict_keys(['pixel_values', 'labels'])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# cifar10_preprocessedのうち10件だけランダムに抜き出したデータセットに対して，trainer.predictを実行する\n",
    "predictions = trainer.predict(cifar10_preprocessed[\"test\"].select(range(33)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-0.9750511 , -1.3120453 , -0.68255013,  7.2387214 , -1.4510149 ,\n",
       "         0.6184644 , -1.412275  , -1.4985118 , -1.291169  , -1.5076542 ],\n",
       "       [ 0.27925816, -0.02822503, -0.8741759 , -1.0265126 , -1.1006895 ,\n",
       "        -0.99763364, -0.7431901 , -1.2049388 ,  8.397488  , -0.7810269 ],\n",
       "       [ 0.9514833 ,  0.42746207, -0.97584736, -1.1565424 , -1.1435704 ,\n",
       "        -1.1687392 , -0.87914205, -1.0246634 ,  7.980294  , -1.0627933 ],\n",
       "       [ 7.6908236 , -1.6353428 , -0.5374553 , -0.46603408, -1.3144487 ,\n",
       "        -1.1595294 , -1.0332788 , -1.0855677 ,  0.0606713 , -1.0656741 ],\n",
       "       [-0.8904549 , -0.88948923, -0.5693022 , -0.78478754, -0.45565078,\n",
       "        -1.289307  ,  8.26966   , -1.0143343 , -0.889244  , -0.6667624 ],\n",
       "       [-0.962662  , -1.1077971 , -1.0339864 , -0.16285956, -0.46044672,\n",
       "        -0.66822964,  8.15542   , -1.0189737 , -1.2799773 , -0.91285896],\n",
       "       [-1.2852596 ,  8.031684  , -1.1237736 , -0.551937  , -0.8456878 ,\n",
       "        -0.73492956, -1.1260903 , -1.0540044 , -1.1210096 ,  0.17944224],\n",
       "       [-0.83858037, -0.90269977, -1.424126  , -0.577043  , -1.1800418 ,\n",
       "        -0.90201586,  8.033724  , -0.9262607 , -0.7890844 ,  0.20885131],\n",
       "       [-1.0441675 , -1.2667131 , -0.79759437,  7.2107654 , -0.7580634 ,\n",
       "        -0.4186208 , -1.5698315 , -1.2728724 , -0.8996796 , -1.2715805 ],\n",
       "       [-1.6717267 ,  7.127752  , -1.5289992 , -1.3241931 , -1.1706802 ,\n",
       "        -1.1304585 , -0.894659  , -1.202345  , -1.08695   ,  3.3426726 ],\n",
       "       [ 7.5841727 , -1.9290448 ,  0.5209193 , -0.40904933, -1.6179984 ,\n",
       "        -0.39732653, -1.1497982 , -1.044112  , -0.9829936 , -1.6176686 ],\n",
       "       [-1.530444  ,  0.22299646, -1.0178258 , -1.037508  , -1.1193877 ,\n",
       "        -0.5514241 , -1.0489587 , -1.1915913 , -0.91852194,  7.961878  ],\n",
       "       [-1.2794101 , -1.6328241 , -1.342996  ,  1.7944223 , -0.36262774,\n",
       "         7.3719735 , -1.858373  , -1.0803127 , -1.6448495 , -1.534175  ],\n",
       "       [-0.71055055, -0.98749447, -0.31612697, -1.2744163 , -0.90114963,\n",
       "        -0.87131983, -0.3938065 ,  8.070474  , -1.0221786 , -1.1376214 ],\n",
       "       [-1.443268  ,  0.09737875, -0.70808214, -1.0252397 , -1.0914583 ,\n",
       "        -0.6203994 , -1.0841184 , -1.0840399 , -1.2355382 ,  7.9288225 ],\n",
       "       [ 0.48063165, -0.86090493, -1.0484617 , -0.9517594 , -0.9242238 ,\n",
       "        -0.8531231 , -0.5859323 , -0.839161  ,  8.321488  , -0.8842376 ],\n",
       "       [-0.6978471 , -1.2341443 , -1.9465191 ,  0.44860798, -0.9072029 ,\n",
       "         7.425051  , -1.5342386 , -0.5749406 , -1.1860275 , -0.7903304 ],\n",
       "       [-0.8438715 , -0.6658082 , -0.6983842 , -1.8937577 , -0.8177632 ,\n",
       "        -0.38123876, -1.0266927 ,  8.079845  , -0.7634291 , -0.4462924 ],\n",
       "       [ 0.17180239, -0.8043202 , -0.8698724 , -0.9839625 , -0.7086497 ,\n",
       "        -0.88277084, -0.92194027, -0.77237403,  8.411846  , -0.7452902 ],\n",
       "       [-0.71728235, -0.82282406, -0.74498785, -0.99072653, -0.646737  ,\n",
       "        -1.2628413 ,  8.257141  , -0.9059668 , -0.7792147 , -0.5229452 ],\n",
       "       [-1.0550342 , -1.3494259 , -1.095137  , -1.0950797 , -0.6525549 ,\n",
       "         0.802532  , -1.156498  ,  8.092398  , -1.168065  , -0.94101804],\n",
       "       [ 7.5848217 , -1.7769158 ,  0.82197356, -0.6328703 , -1.4329537 ,\n",
       "        -1.1533631 , -0.7192893 , -1.4156964 , -0.58530515, -1.4680506 ],\n",
       "       [-1.2150061 , -1.2236857 , -0.48267087, -0.58293664,  7.8200336 ,\n",
       "        -0.79977757, -0.36409184, -0.91102916, -1.1677749 , -1.4181118 ],\n",
       "       [-1.3202226 ,  0.45363253, -1.0132757 , -1.3169945 , -0.9799408 ,\n",
       "        -0.62738675, -1.005885  , -1.1018548 , -1.2959262 ,  7.9356647 ],\n",
       "       [-1.5250448 , -1.1451279 , -1.64776   ,  0.5861762 , -0.19597061,\n",
       "         7.354578  , -1.7306025 , -0.63790935, -1.4360743 , -0.51377213],\n",
       "       [-0.06522899, -1.6659843 ,  7.2470713 , -0.2578823 , -0.5664353 ,\n",
       "        -0.36482638, -1.49518   , -1.0341297 , -1.2985278 , -1.7832246 ],\n",
       "       [-1.2981122 , -1.0133407 , -0.8959341 , -0.4427086 ,  7.8393135 ,\n",
       "        -0.2831453 , -1.2163774 , -0.6944613 , -1.4195311 , -1.1205215 ],\n",
       "       [ 7.8715806 , -1.3082092 , -1.0378314 , -1.0486897 , -1.3651769 ,\n",
       "        -0.8327966 , -0.7280104 , -1.0336052 , -0.23713607, -0.7196937 ],\n",
       "       [-1.3219112 ,  0.62778753, -0.81955045, -1.3472852 , -1.1814551 ,\n",
       "        -0.9559122 , -1.0581923 , -1.2627716 , -0.77667356,  7.9900274 ],\n",
       "       [-0.8382038 , -0.9005525 , -0.79877955, -0.8084911 , -0.69766724,\n",
       "        -0.9821205 ,  8.259218  , -0.9777871 , -0.7242344 , -0.68024385],\n",
       "       [-0.98341846, -0.96471256, -1.083555  , -0.49694037, -0.89214826,\n",
       "        -0.6318238 ,  8.161104  , -0.74357927, -1.1920974 , -0.55560094],\n",
       "       [-1.1415439 , -1.6079688 , -0.55528855,  0.14290147, -0.34629917,\n",
       "         7.504845  , -1.5894262 , -0.7152514 , -1.0947535 , -1.2664796 ],\n",
       "       [-1.9146872 , -1.4616197 , -0.49887833,  1.0798959 ,  7.0705347 ,\n",
       "         0.77830184, -1.1997187 , -1.5783046 , -1.8754714 , -1.5930272 ]],\n",
       "      dtype=float32), label_ids=array([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0,\n",
       "       4, 9, 5, 2, 4, 0, 9, 6, 6, 5, 4]), metrics={'test_loss': 0.0026449381839483976, 'test_accuracy': {'accuracy': 1.0}, 'test_f1': {'f1': 1.0}, 'test_runtime': 2.1525, 'test_samples_per_second': 15.331, 'test_steps_per_second': 0.929})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.predictions[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict training data... #iter = 1563 (50000 samples / 32 batches)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict evaluation data... #iter = 313 (10000 samples / 32 batches)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# データセットのサイズとバッチサイズからイテレーション回数を計算\n",
    "training_args_dict = training_args.to_dict()\n",
    "train_batch_size = training_args_dict[\"per_device_train_batch_size\"]\n",
    "eval_batch_size = training_args_dict[\"per_device_eval_batch_size\"]\n",
    "train_iter = math.ceil(len(cifar10_preprocessed[\"train\"]) / train_batch_size)\n",
    "eval_iter = math.ceil(len(cifar10_preprocessed[\"test\"]) / eval_batch_size)\n",
    "\n",
    "# 訓練・テストデータに対する推論の実行\n",
    "print(f\"predict training data... #iter = {train_iter} ({len(cifar10_preprocessed['train'])} samples / {train_batch_size} batches)\")\n",
    "train_pred = trainer.predict(cifar10_preprocessed[\"train\"])\n",
    "print(f\"predict evaluation data... #iter = {eval_iter} ({len(cifar10_preprocessed['test'])} samples / {eval_batch_size} batches)\")\n",
    "test_pred = trainer.predict(cifar10_preprocessed[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=(array([0.00301972, 0.00218944, 0.00168165, ..., 0.00236561, 0.00414773,\n",
       "       0.00364854], dtype=float32), array([[ 7.4847946 , -0.9837806 , -1.219498  , ..., -1.3068287 ,\n",
       "         1.6573851 , -0.6881158 ],\n",
       "       [-1.0095965 , -0.5473271 , -0.9478028 , ..., -1.1993959 ,\n",
       "        -0.73019946, -0.61273026],\n",
       "       [ 7.719038  , -1.345912  , -1.0711552 , ..., -0.7733431 ,\n",
       "        -0.23427938, -0.9757286 ],\n",
       "       ...,\n",
       "       [-1.2854414 ,  7.546252  , -1.419086  , ..., -1.171309  ,\n",
       "        -0.8146533 ,  2.654647  ],\n",
       "       [-0.9504717 ,  8.123409  , -0.87898463, ..., -1.1007679 ,\n",
       "        -0.873811  , -0.03186027],\n",
       "       [-1.3561383 , -1.3551763 , -1.0653834 , ..., -1.160192  ,\n",
       "        -1.6577327 , -1.7272881 ]], dtype=float32)), label_ids=None, metrics={'test_runtime': 1993.4852, 'test_samples_per_second': 25.082, 'test_steps_per_second': 0.784})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推論結果をnpyで保存する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " array([5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just for check\n",
    "np.unique(np.array(cifar10[\"train\"][\"label\"]), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(cifar10[\"train\"][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_proba_0.npy ((5000, 10)) saved\n",
      "train_proba_1.npy ((5000, 10)) saved\n",
      "train_proba_2.npy ((5000, 10)) saved\n",
      "train_proba_3.npy ((5000, 10)) saved\n",
      "train_proba_4.npy ((5000, 10)) saved\n",
      "train_proba_5.npy ((5000, 10)) saved\n",
      "train_proba_6.npy ((5000, 10)) saved\n",
      "train_proba_7.npy ((5000, 10)) saved\n",
      "train_proba_8.npy ((5000, 10)) saved\n",
      "train_proba_9.npy ((5000, 10)) saved\n"
     ]
    }
   ],
   "source": [
    "# train_pred.predictions[1]をsoftmax関数に通して確率に変換\n",
    "train_pred_proba = torch.nn.functional.softmax(torch.tensor(train_pred.predictions[1]), dim=-1)\n",
    "# train_pred_probaをnumpy配列に変換\n",
    "train_pred_proba = train_pred_proba.cpu().numpy()\n",
    "# ラベルごとに違うファイルとして保存\n",
    "for c in range(len(labels)):\n",
    "    tgt_proba = train_pred_proba[train_labels == c]\n",
    "    # train_pred_probaを保存\n",
    "    np.save(os.path.join(pretrained_dir, \"pred_results\", f\"train_proba_{c}.npy\"), tgt_proba)\n",
    "    print(f\"train_proba_{c}.npy ({tgt_proba.shape}) saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " array([1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just for check\n",
    "np.unique(np.array(cifar10[\"test\"][\"label\"]), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.array(cifar10[\"test\"][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10)\n",
      "test_proba_0.npy ((1000, 10)) saved\n",
      "(1000, 10)\n",
      "test_proba_1.npy ((1000, 10)) saved\n",
      "(1000, 10)\n",
      "test_proba_2.npy ((1000, 10)) saved\n",
      "(1000, 10)\n",
      "test_proba_3.npy ((1000, 10)) saved\n",
      "(1000, 10)\n",
      "test_proba_4.npy ((1000, 10)) saved\n",
      "(1000, 10)\n",
      "test_proba_5.npy ((1000, 10)) saved\n",
      "(1000, 10)\n",
      "test_proba_6.npy ((1000, 10)) saved\n",
      "(1000, 10)\n",
      "test_proba_7.npy ((1000, 10)) saved\n",
      "(1000, 10)\n",
      "test_proba_8.npy ((1000, 10)) saved\n",
      "(1000, 10)\n",
      "test_proba_9.npy ((1000, 10)) saved\n"
     ]
    }
   ],
   "source": [
    "test_pred_proba = torch.nn.functional.softmax(torch.tensor(test_pred.predictions[1]), dim=-1)\n",
    "test_pred_proba = test_pred_proba.cpu().numpy()\n",
    "# ラベルごとに違うファイルとして保存\n",
    "for c in range(len(labels)):\n",
    "    tgt_proba = test_pred_proba[test_labels == c]\n",
    "    print(tgt_proba.shape)\n",
    "    # train_pred_probaを保存\n",
    "    np.save(os.path.join(pretrained_dir, \"pred_results\", f\"test_proba_{c}.npy\"), tgt_proba)\n",
    "    print(f\"test_proba_{c}.npy ({tgt_proba.shape}) saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C10でFine-tuningしたViTモデルのフォワードパスを実行し，C10Cを予測する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初期設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['img', 'label'],\n",
       "    num_rows: 50000\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# デバイス (cuda, or cpu) の取得\n",
    "device = get_device()\n",
    "# datasetをロード (初回の読み込みだけやや時間かかる)\n",
    "dataset_dir = ViTExperiment.DATASET_DIR\n",
    "c10c = load_from_disk(os.path.join(dataset_dir, \"c10c\"))\n",
    "tmp_key = \"zoom_blur\"\n",
    "c10c[tmp_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 読み込まれた時にリアルタイムで前処理を適用するようにする\n",
    "cifar10_preprocessed = c10c[tmp_key].with_transform(transforms)\n",
    "# バッチごとの処理のためのdata_collator\n",
    "data_collator = DefaultDataCollator()\n",
    "# ラベルを示す文字列のlist\n",
    "labels = cifar10_preprocessed.features[\"label\"].names\n",
    "# pretrained modelのロード\n",
    "pretrained_dir = ViTExperiment.OUTPUT_DIR\n",
    "model = ViTForImageClassification.from_pretrained(pretrained_dir).to(device)\n",
    "model.eval()\n",
    "# 学習時の設定をロード\n",
    "training_args = torch.load(os.path.join(pretrained_dir, \"training_args.bin\"))\n",
    "# Trainerオブジェクトの作成\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    eval_dataset=cifar10_preprocessed,\n",
    "    tokenizer=processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推論の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict evaluation data... #iter = 1563 (50000 samples / 32 batches)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='570' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 570/1563 12:02 < 21:00, 0.79 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29669/2176605813.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 推論の実行\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"predict evaluation data... #iter = {eval_iter} ({len(cifar10_preprocessed)} samples / {eval_batch_size} batches)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcifar10_preprocessed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/src/transformers-4.30.2/src/transformers/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3128\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3129\u001b[0m         output = eval_loop(\n\u001b[0;32m-> 3130\u001b[0;31m             \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Prediction\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3131\u001b[0m         )\n\u001b[1;32m   3132\u001b[0m         \u001b[0mtotal_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_batch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/src/transformers-4.30.2/src/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3264\u001b[0m                 )\n\u001b[1;32m   3265\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3266\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pad_across_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3267\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_logits_for_metrics\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3268\u001b[0m                     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_logits_for_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/src/transformers-4.30.2/src/transformers/trainer.py\u001b[0m in \u001b[0;36m_pad_across_processes\u001b[0;34m(self, tensor, pad_index)\u001b[0m\n\u001b[1;32m   3396\u001b[0m         \"\"\"\n\u001b[1;32m   3397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3398\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pad_across_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3399\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3400\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pad_across_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/src/transformers-4.30.2/src/transformers/trainer.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3396\u001b[0m         \"\"\"\n\u001b[1;32m   3397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3398\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pad_across_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3399\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3400\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pad_across_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/src/transformers-4.30.2/src/transformers/trainer.py\u001b[0m in \u001b[0;36m_pad_across_processes\u001b[0;34m(self, tensor, pad_index)\u001b[0m\n\u001b[1;32m   3407\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3408\u001b[0m         \u001b[0;31m# Gather all sizes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3409\u001b[0;31m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3410\u001b[0m         \u001b[0msizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_gather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# データセットのサイズとバッチサイズからイテレーション回数を計算\n",
    "training_args_dict = training_args.to_dict()\n",
    "eval_batch_size = training_args_dict[\"per_device_eval_batch_size\"]\n",
    "eval_iter = math.ceil(len(cifar10_preprocessed) / eval_batch_size)\n",
    "\n",
    "# 推論の実行\n",
    "print(f\"predict evaluation data... #iter = {eval_iter} ({len(cifar10_preprocessed)} samples / {eval_batch_size} batches)\")\n",
    "test_pred = trainer.predict(cifar10_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=(array([0.00530046, 0.4829699 , 0.14570853, ..., 0.31633762, 0.3146287 ,\n",
       "       0.2560988 ], dtype=float32), array([[-0.8668216 , -1.2971003 , -0.75566244, ..., -1.4945534 ,\n",
       "        -1.2481924 , -1.515257  ],\n",
       "       [ 0.3388922 , -0.08191378, -0.8742339 , ..., -1.2310234 ,\n",
       "         8.353749  , -0.87099814],\n",
       "       [ 1.4878969 ,  0.73712045, -1.9341159 , ..., -0.74034   ,\n",
       "         7.126801  ,  0.6780986 ],\n",
       "       ...,\n",
       "       [-0.9040583 , -1.6468737 , -0.5728902 , ..., -0.32825708,\n",
       "        -1.1810881 , -1.380819  ],\n",
       "       [ 5.4605    ,  2.0525274 ,  0.1788212 , ..., -1.6962085 ,\n",
       "        -1.8953818 , -0.3313951 ],\n",
       "       [-1.1177558 , -1.2211878 , -0.4425445 , ...,  8.182668  ,\n",
       "        -0.87377185, -0.9647563 ]], dtype=float32)), label_ids=None, metrics={'test_runtime': 1963.0797, 'test_samples_per_second': 25.47, 'test_steps_per_second': 0.796})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
