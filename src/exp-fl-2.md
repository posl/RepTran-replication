# exp-fl-2: 既存研究との比較

ベースラインとして，
1. ArachneのBL (Bidirectional Fault Localization)
2. 知識ニューロンのIG (Integrated Gradient)

と我々の手法を効果と効率の点で比較する．
ここまでやったらRQ1が終了．FLの結果で論文書けるくらいにはしておく．

# 必要なスクリプト
- 最終層のニューロンごとに integrated_gradient を計算して保存するためのスクリプト（`exp-fl-2-1.py`）
    - 知識ニューロンの論文の方法だと特定するニューロン数を指定できない．
    - そこで，ニューロンごとに，全サンプルにわたったスコアの平均を取り，その上位X件を特定する，という方法にする．Arachneも同様な方法にしたい．
    - 時間も測ってテキストファイルに出しておく．我々の手法との比較は 004a, 005bをするとできる？

- 最終層に ArachneのBL を実行して保存するためのスクリプト（`exp-fl-2-2.py`）
    - ArachneのBLの実装の練習用に，gradient周りについて確認したい（`playground/exp-fl-2-2-1.ipynb`）
- IGとBLそれぞれで特定したlocationに介入を加え，その時の予測結果のnpyを保存するスクリプト (`exp-fl-2-3.py`)
- 上のスクリプトで得られた介入後のモデルの予測結果と，オリジナルモデルの予測結果とのdiffに関するdataframeを作るスクリプト (`exp-fl-2-3.py`)
- それを可視化するためのスクリプト (`exp-fl-2-4.ipynb`)
    - `exp-fl-2-4.py`: コマンドラインからグラフの保存まで実行可能にするためのスクリプト
- 検定のためのスクリプト（`exp-fl-2-5.py`）

# 評価方法
比較手法が増えただけなので基本的には exp-1 と同じ．
integrated gradientはニューロン単位，BLは重み単位の方法になるのでそこは違う．
ただし変更する数は合わせたい．

# 期待する結果
予備実験のようにigで特定したニューロンがenhanceして正解確率を増やせたらおもしろい．
randomよりは変化があってくれ．

# 実際の結果

## 時間の比較
[exp-fl-1の結果にigとblをそれぞれ追加したのを載せる]

## 時間の比較
- ランダム: 当然0
- vdiff: 
- integrated_gradient: 