{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82775a70",
   "metadata": {},
   "source": [
    "# BLのスコア (fwd_imp, grad_loss) と Vdiff の相関をチェックする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82e385c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a21c026f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time, pickle, json, math\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from utils.helper import get_device, json2dict\n",
    "from utils.vit_util import identfy_tgt_misclf, localize_neurons_with_mean_activation, get_batched_hs, get_batched_labels, ViTFromLastLayer, get_ori_model_predictions\n",
    "from utils.constant import ViTExperiment, ExperimentRepair1, Experiment3, ExperimentRepair2, Experiment1, Experiment4\n",
    "from utils.log import set_exp_logging\n",
    "from utils.arachne import calculate_top_n_flattened, calculate_bi_fi\n",
    "from logging import getLogger\n",
    "from datasets import load_from_disk\n",
    "from transformers import ViTForImageClassification\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "logger = getLogger(\"base_logger\")\n",
    "device = get_device()\n",
    "\n",
    "def main(ds_name, k, tgt_rank, misclf_type, fpfn, n, beta=0.5):\n",
    "    print(f\"ds_name: {ds_name}, fold_id: {k}, tgt_rank: {tgt_rank}, misclf_type: {misclf_type}, fpfn: {fpfn}, n: {n}\")\n",
    "    \n",
    "    ts = time.perf_counter()\n",
    "    \n",
    "    # datasetをロード (true_labelsが欲しいので)\n",
    "    ds_dirname = f\"{ds_name}_fold{k}\"\n",
    "    ds = load_from_disk(os.path.join(ViTExperiment.DATASET_DIR, ds_dirname))\n",
    "    label_col = \"fine_label\"\n",
    "    # ラベルの取得 (shuffleされない)\n",
    "    labels = {\n",
    "        \"train\": np.array(ds[\"train\"][label_col]),\n",
    "        \"repair\": np.array(ds[\"repair\"][label_col]),\n",
    "        \"test\": np.array(ds[\"test\"][label_col])\n",
    "    }\n",
    "    tgt_pos = ViTExperiment.CLS_IDX\n",
    "    \n",
    "    # 結果とかログの保存先を先に作っておく\n",
    "    # pretrained modelのディレクトリ\n",
    "    pretrained_dir = getattr(ViTExperiment, ds_name).OUTPUT_DIR.format(k=k)\n",
    "    save_dir = os.path.join(pretrained_dir, f\"misclf_top{tgt_rank}\", f\"{misclf_type}_weights_location\")\n",
    "    if misclf_type == \"all\":\n",
    "        save_dir = os.path.join(pretrained_dir, f\"all_weights_location\")\n",
    "    if fpfn is not None and misclf_type == \"tgt\":\n",
    "        save_dir = os.path.join(pretrained_dir, f\"misclf_top{tgt_rank}\", f\"{misclf_type}_{fpfn}_weights_location\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # tgt_rankの誤分類情報を取り出す\n",
    "    tgt_split = \"repair\" # NOTE: we only use repair split for repairing\n",
    "    tgt_layer = 11 # NOTE: we only use the last layer for repairing\n",
    "    misclf_info_dir = os.path.join(pretrained_dir, \"misclf_info\")\n",
    "    misclf_pair, tgt_label, tgt_mis_indices = identfy_tgt_misclf(misclf_info_dir, tgt_split=tgt_split, tgt_rank=tgt_rank, misclf_type=misclf_type, fpfn=fpfn)\n",
    "    \n",
    "    # original model の repair setの各サンプルに対する正解/不正解のインデックスを取得\n",
    "    pred_res_dir = os.path.join(pretrained_dir, \"pred_results\", \"PredictionOutput\")\n",
    "    if misclf_type == \"tgt\":\n",
    "        ori_pred_labels, is_correct, indices_to_correct, is_correct_others, indices_to_correct_others = get_ori_model_predictions(pred_res_dir, labels, tgt_split=tgt_split, misclf_type=misclf_type, tgt_label=tgt_label)\n",
    "    else:\n",
    "        ori_pred_labels, is_correct, indices_to_correct = get_ori_model_predictions(pred_res_dir, labels, tgt_split=tgt_split, misclf_type=misclf_type, tgt_label=tgt_label)\n",
    "    print(f\"len(indices_to_correct): {len(indices_to_correct)}, len(tgt_mis_indices): {len(tgt_mis_indices)}\")\n",
    "    \n",
    "    # 中間ニューロン値のキャッシュのロード\n",
    "    mid_cache_dir = os.path.join(pretrained_dir, f\"cache_states_{tgt_split}\")\n",
    "    mid_save_path = os.path.join(mid_cache_dir, f\"intermediate_states_l{tgt_layer}.pt\")\n",
    "    cached_mid_states = torch.load(mid_save_path, map_location=\"cpu\") # (tgt_splitのサンプル数(10000), 中間ニューロン数(3072))\n",
    "    # cached_mid_statesをnumpy配列にする\n",
    "    cached_mid_states = cached_mid_states.detach().numpy().copy()\n",
    "    print(f\"cached_mid_states.shape: {cached_mid_states.shape}\")\n",
    "\n",
    "    # ===============================================\n",
    "    # localization phase\n",
    "    # ===============================================\n",
    "\n",
    "    if misclf_type == \"src_tgt\" or misclf_type == \"tgt\":\n",
    "        vscore_before_dir = os.path.join(pretrained_dir, f\"misclf_top{tgt_rank}\", \"vscores_before\")\n",
    "        vscore_dir = os.path.join(pretrained_dir, f\"misclf_top{tgt_rank}\", \"vscores\")\n",
    "        vscore_after_dir = os.path.join(pretrained_dir, f\"misclf_top{tgt_rank}\", \"vscores_after\")\n",
    "    elif misclf_type == \"all\":\n",
    "        vscore_before_dir = os.path.join(pretrained_dir, \"vscores_before\")\n",
    "        vscore_dir = os.path.join(pretrained_dir, \"vscores\")\n",
    "        vscore_after_dir = os.path.join(pretrained_dir, \"vscores_after\")\n",
    "    # vscoreとmean_activationを用いたlocalizationを実行\n",
    "    places_to_neuron, tgt_neuron_score, neuron_scores = localize_neurons_with_mean_activation(vscore_before_dir, vscore_dir, vscore_after_dir, tgt_layer, n=None, intermediate_states=cached_mid_states, tgt_mis_indices=tgt_mis_indices, misclf_pair=misclf_pair, tgt_label=tgt_label, fpfn=fpfn, return_all_neuron_score=True, vscore_abs=True, covavg=False, vscore_cor_dir=os.path.join(pretrained_dir, \"vscores\"))\n",
    "    # log表示\n",
    "    # logger.info(f\"places_to_neuron={places_to_neuron}\")\n",
    "    # logger.info(f\"num(pos_to_fix)={len(places_to_neuron)}\")\n",
    "    # 位置情報を保存\n",
    "    # print(f\"len(places_to_neuron): {len(places_to_neuron)}\")\n",
    "    # print(f\"tgt_neuron_score.shape: {tgt_neuron_score.shape}\")\n",
    "    # print(f\"tgt_neuron_score: {tgt_neuron_score}\")\n",
    "    print(f\"neuron_scores.shape: {neuron_scores.shape}\")\n",
    "    print(f\"neuron_scores: {neuron_scores}\")\n",
    "    \n",
    "    # ============================================================\n",
    "    # ここまでで Vdiff x Use_i によるニューロンごとのスコア計算ができたので，次は勾配も使った重み特定をする．\n",
    "    # ============================================================\n",
    "    \n",
    "    # キャッシュの保存用のディレクトリ\n",
    "    cache_dir = os.path.join(pretrained_dir, f\"cache_hidden_states_before_layernorm_{tgt_split}\")\n",
    "    cache_path = os.path.join(cache_dir, f\"hidden_states_before_layernorm_{tgt_layer}.npy\")\n",
    "    # cache_pathに存在することを確認\n",
    "    assert os.path.exists(cache_path), f\"cache_path: {cache_path} does not exist.\"\n",
    "    # vit_utilsの関数を使ってバッチを取得\n",
    "    batch_size = ViTExperiment.BATCH_SIZE\n",
    "    \n",
    "    # 正解サンプル (I_pos) と誤りサンプル (I_neg) を分割\n",
    "    correct_batched_hidden_states = get_batched_hs(cache_path, batch_size, indices_to_correct)\n",
    "    correct_batched_labels = get_batched_labels(labels[tgt_split], batch_size, indices_to_correct)\n",
    "    incorrect_batched_hidden_states = get_batched_hs(cache_path, batch_size, tgt_mis_indices)\n",
    "    incorrect_batched_labels = get_batched_labels(labels[tgt_split], batch_size, tgt_mis_indices)\n",
    "    \n",
    "    # hidden_states_before_layernormのshapeを確認\n",
    "    assert len(correct_batched_hidden_states) == len(correct_batched_labels), f\"len(correct_batched_hidden_states): {len(correct_batched_hidden_states)}, len(correct_batched_labels): {len(correct_batched_labels)}\"\n",
    "    assert len(incorrect_batched_hidden_states) == len(incorrect_batched_labels), f\"len(incorrect_batched_hidden_states): {len(incorrect_batched_hidden_states)}, len(incorrect_batched_labels): {len(incorrect_batched_labels)}\"\n",
    "    \n",
    "    # ロスの勾配の取得に必要なモデルをロード\n",
    "    model = ViTForImageClassification.from_pretrained(pretrained_dir).to(device)\n",
    "    model.eval()\n",
    "    vit_from_last_layer = ViTFromLastLayer(model)\n",
    "    vit_from_last_layer.eval()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    \n",
    "    # =========================================\n",
    "    # BIとFIの計算\n",
    "    # =========================================\n",
    "    \n",
    "    # 全体の grad_loss と fwd_imp を統合\n",
    "    grad_loss_list = [] # [Wbefに対するgrad_loss, Waftに対するgrad_loss]\n",
    "    fwd_imp_list = []  # [Wbefに対するfwd_imp, Waftに対するfwd_imp]\n",
    "    # 正解サンプルに対するBI, FI\n",
    "    print(f\"Calculating BI and FI... (correct samples)\")\n",
    "    pos_results = calculate_bi_fi(\n",
    "        indices_to_correct,\n",
    "        correct_batched_hidden_states,\n",
    "        correct_batched_labels,\n",
    "        vit_from_last_layer,\n",
    "        optimizer,\n",
    "        tgt_pos,\n",
    "    )\n",
    "    # 誤りサンプルに対するBI, FI\n",
    "    print(f\"Calculating BI and FI... (incorrect samples)\")\n",
    "    neg_results = calculate_bi_fi(\n",
    "        tgt_mis_indices,\n",
    "        incorrect_batched_hidden_states,\n",
    "        incorrect_batched_labels,\n",
    "        vit_from_last_layer,\n",
    "        optimizer,\n",
    "        tgt_pos,\n",
    "    )\n",
    "    # \"before\" と \"after\" のそれぞれで計算\n",
    "    for ba in [\"before\", \"after\"]:\n",
    "        # Gradient Loss (Arachne Algorithm1 L6)\n",
    "        grad_loss = neg_results[ba][\"bw\"] / (1 + pos_results[ba][\"bw\"])\n",
    "        print(f\"{ba} - grad_loss.shape: {grad_loss.shape}\")  # shape: (out_dim, in_dim)\n",
    "        grad_loss_list.append(grad_loss)\n",
    "\n",
    "        # Forward Impact (Arachne Algorithm1 L9)\n",
    "        fwd_imp = neg_results[ba][\"fw\"] / (1 + pos_results[ba][\"fw\"])\n",
    "        print(f\"{ba} - fwd_imp.shape: {fwd_imp.shape}\")  # shape: (out_dim, in_dim)\n",
    "        fwd_imp_list.append(fwd_imp)\n",
    "\n",
    "        # \"before\" の out_dim を取得\n",
    "        if ba == \"before\":\n",
    "            out_dim_before = grad_loss.shape[0]  # out_dim_before = out_dim\n",
    "\n",
    "    # forward/backward impacts の weighted sum\n",
    "    print(\"Calculating top n for target weights...\")\n",
    "    identified_indices = calculate_top_n_flattened(grad_loss_list, fwd_imp_list, n=None)\n",
    "    print(f\"len(identified_indices['bef']): {len(identified_indices['bef'])}, len(identified_indices['aft']): {len(identified_indices['aft'])}\")\n",
    "    \n",
    "    # \"before\" と \"after\" に分けて格納\n",
    "    pos_before = identified_indices[\"bef\"]\n",
    "    pos_after = identified_indices[\"aft\"]\n",
    "    # 重みごとのスコア\n",
    "    weighted_scores = identified_indices[\"scores\"]\n",
    "    assert len(weighted_scores) == len(pos_before) + len(pos_after), f\"len(weighted_scores): {len(weighted_scores)}, len(pos_before): {len(pos_before)}, len(pos_after): {len(pos_after)}\"\n",
    "    \n",
    "    # 結果の出力\n",
    "    print(f\"pos_before.shape: {pos_before.shape}, pos_after.shape: {pos_after.shape}\")\n",
    "    print(f\"len(weighted scores): {len(weighted_scores)}\")\n",
    "    \n",
    "    # 終了時刻\n",
    "    te = time.perf_counter()\n",
    "    elapsed_time = te - ts\n",
    "    print(f\"elapsed_time: {elapsed_time:.2f} sec\")\n",
    "    return neuron_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7670cc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start: ds=c100, k=0, n=12, beta=0.1, tgt_rank=1, misclf_type=src_tgt, fpfn=None\n",
      "====================================================================\n",
      "ds_name: c100, fold_id: 0, tgt_rank: 1, misclf_type: src_tgt, fpfn: None, n: 12\n",
      "len(indices_to_correct): 9074, len(tgt_mis_indices): 19\n",
      "cached_mid_states.shape: (10000, 3072)\n",
      "0.0 1.0 0.036937162 0.08774388\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20991/2151442785.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmisclf_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"all\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtgt_rank\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# misclf_type == \"all\"の時にtgt_rankは関係ないのでこのループもスキップすべき\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_rank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmisclf_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"ds\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"k\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"beta\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tgt_rank\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtgt_rank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"misclf_type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmisclf_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fpfn\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfpfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"elapsed_time\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0melapsed_time\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# results を csv にして保存\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_20991/2757938413.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(ds_name, k, tgt_rank, misclf_type, fpfn, n, beta)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mvscore_after_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"vscores_after\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# vscoreとmean_activationを用いたlocalizationを実行\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mplaces_to_neuron\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_neuron_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneuron_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocalize_neurons_with_mean_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvscore_before_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvscore_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvscore_after_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintermediate_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcached_mid_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mis_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_mis_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmisclf_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmisclf_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfpfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_all_neuron_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvscore_abs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovavg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvscore_cor_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"vscores\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0;31m# log表示\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# logger.info(f\"places_to_neuron={places_to_neuron}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "ds = \"c100\"\n",
    "# k_list = range(5)\n",
    "k_list = [0]\n",
    "tgt_rank_list = range(1, 6)\n",
    "# misclf_type_list = [\"all\", \"src_tgt\", \"tgt\"]\n",
    "misclf_type_list = [\"src_tgt\", \"tgt\"]\n",
    "fpfn_list = [None, \"fp\", \"fn\"]\n",
    "n_list = [Experiment4.NUM_IDENTIFIED_WEIGHTS]\n",
    "# n_list = [Experiment1.NUM_IDENTIFIED_WEIGHTS, ExperimentRepair1.NUM_IDENTIFIED_WEIGHTS, ExperimentRepair2.NUM_IDENTIFIED_WEIGHTS, Experiment4.NUM_IDENTIFIED_WEIGHTS]\n",
    "n_str = \"_\".join([str(n) for n in n_list])\n",
    "beta_list = [0.1, 0.25, 0.5, 0.75, 1.0]\n",
    "\n",
    "results = []\n",
    "for k, tgt_rank, misclf_type, fpfn, n, beta in product(k_list, tgt_rank_list, misclf_type_list, fpfn_list, n_list, beta_list):\n",
    "    print(f\"\\nStart: ds={ds}, k={k}, n={n}, beta={beta}, tgt_rank={tgt_rank}, misclf_type={misclf_type}, fpfn={fpfn}\\n====================================================================\")\n",
    "    if (misclf_type == \"src_tgt\" or misclf_type == \"all\") and fpfn is not None: # misclf_type == \"src_tgt\" or \"all\"の時はfpfnはNoneだけでいい\n",
    "        continue\n",
    "    if misclf_type == \"all\" and tgt_rank != 1: # misclf_type == \"all\"の時にtgt_rankは関係ないのでこのループもスキップすべき\n",
    "        continue\n",
    "    elapsed_time = main(ds, k, tgt_rank, misclf_type, fpfn, n=n, beta=beta)\n",
    "    results.append({\"ds\": ds, \"k\": k, \"n\": n, \"beta\": beta, \"tgt_rank\": tgt_rank, \"misclf_type\": misclf_type, \"fpfn\": fpfn, \"elapsed_time\": elapsed_time})\n",
    "# results を csv にして保存\n",
    "# result_df = pd.DataFrame(results)\n",
    "# result_df.to_csv(f\"./exp-fl-8-1_time_n{n_str}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc8b223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3f5c39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
